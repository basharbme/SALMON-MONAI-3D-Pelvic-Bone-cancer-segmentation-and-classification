{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy2 of Pelvic Bone Tumour 3d segmentation Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basharbme/3D-Pelvic-Bone-cancer-classification/blob/main/Copy_of_Copy2_of_Pelvic_Bone_Tumour_3d_segmentation_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAGUSIA2BzbE",
        "outputId": "672facfd-f40c-4cff-cfb9-3e599453015c"
      },
      "source": [
        "!pip install SimpleITK==2.1.0\n",
        "!pip install torchsummaryX\n",
        "!pip install nibabel\n",
        "!pip install pillow\n",
        "!pip install tensorboard\n",
        "!pip install gdown\n",
        "!pip install pytorch-ignite==0.4.4\n",
        "!pip install itk\n",
        "!pip install tqdm\n",
        "!pip install lmdb\n",
        "!pip install psutil\n",
        "!pip install pandas\n",
        "!pip install einops\n",
        "!pip install scikit-image\n",
        "!pip install 'monai[all]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK==2.1.0\n",
            "  Downloading SimpleITK-2.1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 33 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.0\n",
            "Collecting torchsummaryX\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.9.0+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchsummaryX) (3.7.4.3)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from nibabel) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.41.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Collecting pytorch-ignite==0.4.4\n",
            "  Downloading pytorch_ignite-0.4.4-py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite==0.4.4) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite==0.4.4) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.4\n",
            "Collecting itk\n",
            "  Downloading itk-5.2.1.post1-cp37-cp37m-manylinux2014_x86_64.whl (8.3 kB)\n",
            "Collecting itk-segmentation==5.2.1.post1\n",
            "  Downloading itk_segmentation-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6 MB 154 kB/s \n",
            "\u001b[?25hCollecting itk-numerics==5.2.1.post1\n",
            "  Downloading itk_numerics-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 8.4 kB/s \n",
            "\u001b[?25hCollecting itk-io==5.2.1.post1\n",
            "  Downloading itk_io-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.0 MB 146 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from itk) (1.19.5)\n",
            "Collecting itk-registration==5.2.1.post1\n",
            "  Downloading itk_registration-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.3 MB 10.6 MB/s \n",
            "\u001b[?25hCollecting itk-core==5.2.1.post1\n",
            "  Downloading itk_core-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (70.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 70.6 MB 2.8 kB/s \n",
            "\u001b[?25hCollecting itk-filtering==5.2.1.post1\n",
            "  Downloading itk_filtering-5.2.1.post1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (95.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 95.3 MB 12 kB/s \n",
            "\u001b[?25hInstalling collected packages: itk-core, itk-numerics, itk-filtering, itk-segmentation, itk-registration, itk-io, itk\n",
            "Successfully installed itk-5.2.1.post1 itk-core-5.2.1.post1 itk-filtering-5.2.1.post1 itk-io-5.2.1.post1 itk-numerics-5.2.1.post1 itk-registration-5.2.1.post1 itk-segmentation-5.2.1.post1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (0.99)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting einops\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.2\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "Collecting monai[all]\n",
            "  Downloading monai-0.7.0-202109240007-py3-none-any.whl (650 kB)\n",
            "\u001b[K     |████████████████████████████████| 650 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from monai[all]) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.5 in /usr/local/lib/python3.7/dist-packages (from monai[all]) (1.9.0+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from monai[all]) (1.1.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from monai[all]) (7.1.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from monai[all]) (2.6.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from monai[all]) (0.99)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from monai[all]) (0.3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from monai[all]) (0.10.0+cu111)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from monai[all]) (5.4.8)\n",
            "Collecting cucim>=21.8.2\n",
            "  Downloading cucim-21.10.0-py3-none-manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itk>=5.2 in /usr/local/lib/python3.7/dist-packages (from monai[all]) (5.2.1.post1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from monai[all]) (0.16.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from monai[all]) (3.0.2)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.7/dist-packages (from monai[all]) (4.62.3)\n",
            "Requirement already satisfied: gdown>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from monai[all]) (3.6.4)\n",
            "Collecting openslide-python==1.1.2\n",
            "  Downloading openslide-python-1.1.2.tar.gz (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 40.2 MB/s \n",
            "\u001b[?25hCollecting pytorch-ignite==0.4.5\n",
            "  Downloading pytorch_ignite-0.4.5-py3-none-any.whl (221 kB)\n",
            "\u001b[K     |████████████████████████████████| 221 kB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from cucim>=21.8.2->monai[all]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown>=3.6.4->monai[all]) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.6.4->monai[all]) (1.15.0)\n",
            "Requirement already satisfied: itk-io==5.2.1.post1 in /usr/local/lib/python3.7/dist-packages (from itk>=5.2->monai[all]) (5.2.1.post1)\n",
            "Requirement already satisfied: itk-numerics==5.2.1.post1 in /usr/local/lib/python3.7/dist-packages (from itk>=5.2->monai[all]) (5.2.1.post1)\n",
            "Requirement already satisfied: itk-filtering==5.2.1.post1 in /usr/local/lib/python3.7/dist-packages (from itk>=5.2->monai[all]) (5.2.1.post1)\n",
            "Requirement already satisfied: itk-segmentation==5.2.1.post1 in /usr/local/lib/python3.7/dist-packages (from itk>=5.2->monai[all]) (5.2.1.post1)\n",
            "Requirement already satisfied: itk-core==5.2.1.post1 in /usr/local/lib/python3.7/dist-packages (from itk>=5.2->monai[all]) (5.2.1.post1)\n",
            "Requirement already satisfied: itk-registration==5.2.1.post1 in /usr/local/lib/python3.7/dist-packages (from itk>=5.2->monai[all]) (5.2.1.post1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->monai[all]) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->monai[all]) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->monai[all]) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->monai[all]) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->monai[all]) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->monai[all]) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->monai[all]) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->monai[all]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2->monai[all]) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5->monai[all]) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->monai[all]) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown>=3.6.4->monai[all]) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown>=3.6.4->monai[all]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown>=3.6.4->monai[all]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown>=3.6.4->monai[all]) (2.10)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (0.37.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (1.41.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->monai[all]) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->monai[all]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->monai[all]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->monai[all]) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->monai[all]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->monai[all]) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->monai[all]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->monai[all]) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->monai[all]) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->monai[all]) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->monai[all]) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->monai[all]) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 31.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 40.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->monai[all]) (1.0.1)\n",
            "Building wheels for collected packages: openslide-python\n",
            "  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openslide-python: filename=openslide_python-1.1.2-cp37-cp37m-linux_x86_64.whl size=27703 sha256=a4b3bcac75e2d0e74059758633414a6d8835b0c8fbd85fbfd8c7c12bb608baa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/c3/97/980962653f9305314bfb6d93f80be5e21f13e206af66fc7ad3\n",
            "Successfully built openslide-python\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, pytorch-ignite, openslide-python, monai, cucim\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pytorch-ignite\n",
            "    Found existing installation: pytorch-ignite 0.4.4\n",
            "    Uninstalling pytorch-ignite-0.4.4:\n",
            "      Successfully uninstalled pytorch-ignite-0.4.4\n",
            "Successfully installed cucim-21.10.0 huggingface-hub-0.0.19 monai-0.7.0 openslide-python-1.1.2 pytorch-ignite-0.4.5 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-guxCwow8cW",
        "outputId": "90a77a3d-4e2c-48f4-d4f6-9af8048064bf"
      },
      "source": [
        "!pip install keras\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICv5WFIprvme"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYZ8X30Fryyw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOg40JrEXWDY",
        "outputId": "37723c4a-3ad4-458b-e795-0d4c1afa510d"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import monai\n",
        "import time\n",
        "# from networks import build_net\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "from glob import glob\n",
        "from ignite.metrics import Accuracy\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import argparse\n",
        "from monai.data import CacheDataset, DataLoader, Dataset\n",
        "import SimpleITK as sitk\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.data import NiftiSaver, create_test_image_3d, list_data_collate\n",
        "from collections import OrderedDict\n",
        "from monai.handlers import (MeanDice, StatsHandler, ValidationHandler, CheckpointSaver, LrScheduleHandler, CheckpointLoader,\n",
        "                         SegmentationSaver, TensorBoardImageHandler, TensorBoardStatsHandler)\n",
        "from monai.inferers import SimpleInferer, SlidingWindowInferer\n",
        "from monai.utils import set_determinism\n",
        "import re\n",
        "from monai.data import create_test_image_3d, list_data_collate\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.transforms import (Activationsd,MeanEnsembled, GaussianSmoothd, CropForegroundd, ThresholdIntensityd, Activations,AsDiscrete, LoadImaged, AsChannelFirstd, VoteEnsembled, AsDiscreted, Compose, AddChanneld, Transpose, ConcatItemsd,\n",
        "                              ScaleIntensityd, Resized,ToTensord, RandSpatialCropd, Rand3DElasticd, RandAffined, RandGaussianSmoothd, SpatialPadd,\n",
        "    Spacingd, Orientationd, RandShiftIntensityd, BorderPadd, RandGaussianNoised, RandAdjustContrastd,NormalizeIntensityd,RandFlipd, KeepLargestConnectedComponent)\n",
        "\n",
        "from monai.engines import (\n",
        "    EnsembleEvaluator,\n",
        "    SupervisedEvaluator,\n",
        "    SupervisedTrainer\n",
        ")\n",
        "\n",
        "from skimage.measure import label\n",
        "def getLargestCC(segmentation):\n",
        "    labels = label(segmentation)\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    list_seg=list(zip(unique, counts))[1:] # the 0 label is by default background so take the rest\n",
        "    largest=max(list_seg, key=lambda x:x[1])[0]\n",
        "    labels_max=(labels == largest).astype(int)\n",
        "    return labels_max\n",
        "\n",
        "\n",
        "def Padding(image, reference):\n",
        "\n",
        "\n",
        "    size_new = reference.GetSize()\n",
        "\n",
        "    output_size = tuple(size_new)\n",
        "\n",
        "    resampler = sitk.ResampleImageFilter()\n",
        "    resampler.SetOutputSpacing(reference.GetSpacing())\n",
        "    resampler.SetSize(output_size)\n",
        "\n",
        "    # resample on label\n",
        "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
        "    resampler.SetOutputOrigin(reference.GetOrigin())\n",
        "    resampler.SetOutputDirection(reference.GetDirection())\n",
        "\n",
        "    image = resampler.Execute(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def resize(img, new_size, interpolator):\n",
        "    # img = sitk.ReadImage(img)\n",
        "    dimension = img.GetDimension()\n",
        "\n",
        "    # Physical image size corresponds to the largest physical size in the training set, or any other arbitrary size.\n",
        "    reference_physical_size = np.zeros(dimension)\n",
        "\n",
        "    reference_physical_size[:] = [(sz - 1) * spc if sz * spc > mx else mx for sz, spc, mx in\n",
        "                                  zip(img.GetSize(), img.GetSpacing(), reference_physical_size)]\n",
        "\n",
        "    # Create the reference image with a zero origin, identity direction cosine matrix and dimension\n",
        "    reference_origin = np.zeros(dimension)\n",
        "    reference_direction = np.identity(dimension).flatten()\n",
        "    reference_size = new_size\n",
        "    reference_spacing = [phys_sz / (sz - 1) for sz, phys_sz in zip(reference_size, reference_physical_size)]\n",
        "\n",
        "    reference_image = sitk.Image(reference_size, img.GetPixelIDValue())\n",
        "    reference_image.SetOrigin(reference_origin)\n",
        "    reference_image.SetSpacing(reference_spacing)\n",
        "    reference_image.SetDirection(reference_direction)\n",
        "\n",
        "    # Always use the TransformContinuousIndexToPhysicalPoint to compute an indexed point's physical coordinates as\n",
        "    # this takes into account size, spacing and direction cosines. For the vast majority of images the direction\n",
        "    # cosines are the identity matrix, but when this isn't the case simply multiplying the central index by the\n",
        "    # spacing will not yield the correct coordinates resulting in a long debugging session.\n",
        "    reference_center = np.array(\n",
        "        reference_image.TransformContinuousIndexToPhysicalPoint(np.array(reference_image.GetSize()) / 2.0))\n",
        "\n",
        "    # Transform which maps from the reference_image to the current img with the translation mapping the image\n",
        "    # origins to each other.\n",
        "    transform = sitk.AffineTransform(dimension)\n",
        "    transform.SetMatrix(img.GetDirection())\n",
        "    transform.SetTranslation(np.array(img.GetOrigin()) - reference_origin)\n",
        "    # Modify the transformation to align the centers of the original and reference image instead of their origins.\n",
        "    centering_transform = sitk.TranslationTransform(dimension)\n",
        "    img_center = np.array(img.TransformContinuousIndexToPhysicalPoint(np.array(img.GetSize()) / 2.0))\n",
        "    centering_transform.SetOffset(np.array(transform.GetInverse().TransformPoint(img_center) - reference_center))\n",
        "\n",
        "    # centered_transform = sitk.Transform(transform)\n",
        "    # centered_transform.AddTransform(centering_transform)\n",
        "\n",
        "    centered_transform = sitk.CompositeTransform([transform, centering_transform])\n",
        "\n",
        "    # Using the linear interpolator as these are intensity images, if there is a need to resample a ground truth\n",
        "    # segmentation then the segmentation image should be resampled using the NearestNeighbor interpolator so that\n",
        "    # no new labels are introduced.\n",
        "\n",
        "    return sitk.Resample(img, reference_image, centered_transform, interpolator, 0.0)\n",
        "\n",
        "\n",
        "def resample_sitk_image(sitk_image, spacing=None, interpolator=None, fill_value=0):\n",
        "    # https://github.com/SimpleITK/SlicerSimpleFilters/blob/master/SimpleFilters/SimpleFilters.py\n",
        "    _SITK_INTERPOLATOR_DICT = {\n",
        "        'nearest': sitk.sitkNearestNeighbor,\n",
        "        'linear': sitk.sitkLinear,\n",
        "        'gaussian': sitk.sitkGaussian,\n",
        "        'label_gaussian': sitk.sitkLabelGaussian,\n",
        "        'bspline': sitk.sitkBSpline,\n",
        "        'hamming_sinc': sitk.sitkHammingWindowedSinc,\n",
        "        'cosine_windowed_sinc': sitk.sitkCosineWindowedSinc,\n",
        "        'welch_windowed_sinc': sitk.sitkWelchWindowedSinc,\n",
        "        'lanczos_windowed_sinc': sitk.sitkLanczosWindowedSinc\n",
        "    }\n",
        "\n",
        "    if isinstance(sitk_image, str):\n",
        "        sitk_image = sitk.ReadImage(sitk_image)\n",
        "    num_dim = sitk_image.GetDimension()\n",
        "\n",
        "    if not interpolator:\n",
        "        interpolator = 'linear'\n",
        "        pixelid = sitk_image.GetPixelIDValue()\n",
        "\n",
        "        if pixelid not in [1, 2, 4]:\n",
        "            raise NotImplementedError(\n",
        "                'Set `interpolator` manually, '\n",
        "                'can only infer for 8-bit unsigned or 16, 32-bit signed integers')\n",
        "        if pixelid == 1:  # 8-bit unsigned int\n",
        "            interpolator = 'nearest'\n",
        "\n",
        "    orig_pixelid = sitk_image.GetPixelIDValue()\n",
        "    orig_origin = sitk_image.GetOrigin()\n",
        "    orig_direction = sitk_image.GetDirection()\n",
        "    orig_spacing = np.array(sitk_image.GetSpacing())\n",
        "    orig_size = np.array(sitk_image.GetSize(), dtype=np.int)\n",
        "\n",
        "    if not spacing:\n",
        "        min_spacing = orig_spacing.min()\n",
        "        new_spacing = [min_spacing] * num_dim\n",
        "    else:\n",
        "        new_spacing = [float(s) for s in spacing]\n",
        "\n",
        "    assert interpolator in _SITK_INTERPOLATOR_DICT.keys(), \\\n",
        "        '`interpolator` should be one of {}'.format(_SITK_INTERPOLATOR_DICT.keys())\n",
        "\n",
        "    sitk_interpolator = _SITK_INTERPOLATOR_DICT[interpolator]\n",
        "\n",
        "    new_size = orig_size * (orig_spacing / new_spacing)\n",
        "    new_size = np.ceil(new_size).astype(np.int)  # Image dimensions are in integers\n",
        "    new_size = [int(s) for s in new_size]  # SimpleITK expects lists, not ndarrays\n",
        "\n",
        "    resample_filter = sitk.ResampleImageFilter()\n",
        "\n",
        "    resample_filter.SetOutputSpacing(new_spacing)\n",
        "    resample_filter.SetSize(new_size)\n",
        "    resample_filter.SetOutputDirection(orig_direction)\n",
        "    resample_filter.SetOutputOrigin(orig_origin)\n",
        "    resample_filter.SetTransform(sitk.Transform())\n",
        "    resample_filter.SetDefaultPixelValue(orig_pixelid)\n",
        "    resample_filter.SetInterpolator(sitk_interpolator)\n",
        "    resample_filter.SetDefaultPixelValue(fill_value)\n",
        "\n",
        "    resampled_sitk_image = resample_filter.Execute(sitk_image)\n",
        "\n",
        "    return resampled_sitk_image\n",
        "\n",
        "\n",
        "def numericalSort(value):\n",
        "    numbers = re.compile(r'(\\d+)')\n",
        "    parts = numbers.split(value)\n",
        "    parts[1::2] = map(int, parts[1::2])\n",
        "    return parts\n",
        "\n",
        "\n",
        "def lstFiles(Path):\n",
        "\n",
        "    images_list = []  # create an empty list, the raw image data files is stored here\n",
        "    for dirName, subdirList, fileList in os.walk(Path):\n",
        "        for filename in fileList:\n",
        "            if \".nii.gz\" in filename.lower():\n",
        "                images_list.append(os.path.join(dirName, filename))\n",
        "            elif \".nii\" in filename.lower():\n",
        "                images_list.append(os.path.join(dirName, filename))\n",
        "            elif \".mhd\" in filename.lower():\n",
        "                images_list.append(os.path.join(dirName, filename))\n",
        "\n",
        "    images_list = sorted(images_list, key=numericalSort)\n",
        "\n",
        "    return images_list\n",
        "\n",
        "\n",
        "def new_state_dict(file_name):\n",
        "    state_dict = torch.load(file_name)\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        if k[:6] == 'module':\n",
        "            name = k[7:]\n",
        "            new_state_dict[name] = v\n",
        "        else:\n",
        "            new_state_dict[k] = v\n",
        "    return new_state_dict\n",
        "\n",
        "\n",
        "def new_state_dict_cpu(file_name):\n",
        "    state_dict = torch.load(file_name, map_location='cpu')\n",
        "    new_state_dict_cpu = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        if k[:6] == 'module':\n",
        "            name = k[7:]\n",
        "            new_state_dict_cpu[name] = v\n",
        "        else:\n",
        "            new_state_dict_cpu[k] = v\n",
        "    return new_state_dict_cpu\n",
        "\n",
        "\n",
        "def from_numpy_to_itk(image_np, image_itk):\n",
        "\n",
        "    # read image file\n",
        "    reader = sitk.ImageFileReader()\n",
        "    reader.SetFileName(image_itk)\n",
        "    image_itk = reader.Execute()\n",
        "\n",
        "    image_np = np.transpose(image_np, (2, 1, 0))\n",
        "    image = sitk.GetImageFromArray(image_np)\n",
        "    image.SetDirection(image_itk.GetDirection())\n",
        "    image.SetSpacing(image_itk.GetSpacing())\n",
        "    image.SetOrigin(image_itk.GetOrigin())\n",
        "    return image\n",
        "\n",
        "\n",
        "# function to keep track of the cropped area and coordinates\n",
        "def statistics_crop(image, resolution):\n",
        "\n",
        "    files = [{\"image\": image}]\n",
        "\n",
        "    reader = sitk.ImageFileReader()\n",
        "    reader.SetFileName(image)\n",
        "    image_itk = reader.Execute()\n",
        "    original_resolution = image_itk.GetSpacing()\n",
        "\n",
        "    # original size\n",
        "    transforms = Compose([\n",
        "        LoadImaged(keys=['image']),\n",
        "        AddChanneld(keys=['image']),\n",
        "        ToTensord(keys=['image'])])\n",
        "    data = monai.data.Dataset(data=files, transform=transforms)\n",
        "    loader = DataLoader(data, batch_size=1, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "    loader = monai.utils.misc.first(loader)\n",
        "    im, = (loader['image'][0])\n",
        "    vol = im.numpy()\n",
        "    original_shape = vol.shape\n",
        "\n",
        "    # cropped foreground size\n",
        "    transforms = Compose([\n",
        "        LoadImaged(keys=['image']),\n",
        "        AddChanneld(keys=['image']),\n",
        "        CropForegroundd(keys=['image'], source_key='image', start_coord_key='foreground_start_coord',\n",
        "                        end_coord_key='foreground_end_coord', ),  # crop CropForeground\n",
        "        ToTensord(keys=['image', 'foreground_start_coord', 'foreground_end_coord'])])\n",
        "\n",
        "    data = monai.data.Dataset(data=files, transform=transforms)\n",
        "    loader = DataLoader(data, batch_size=1, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "    loader = monai.utils.misc.first(loader)\n",
        "    im, coord1, coord2 = (loader['image'][0], loader['foreground_start_coord'][0], loader['foreground_end_coord'][0])\n",
        "    vol = im[0].numpy()\n",
        "    coord1 = coord1.numpy()\n",
        "    coord2 = coord2.numpy()\n",
        "    crop_shape = vol.shape\n",
        "\n",
        "    if resolution is not None:\n",
        "\n",
        "        transforms = Compose([\n",
        "            LoadImaged(keys=['image']),\n",
        "            AddChanneld(keys=['image']),\n",
        "            CropForegroundd(keys=['image'], source_key='image'),  # crop CropForeground\n",
        "            Spacingd(keys=['image'], pixdim=resolution, mode=('bilinear')),  # resolution\n",
        "            ToTensord(keys=['image'])])\n",
        "\n",
        "        data = monai.data.Dataset(data=files, transform=transforms)\n",
        "        loader = DataLoader(data, batch_size=1, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "        loader = monai.utils.misc.first(loader)\n",
        "        im, = (loader['image'][0])\n",
        "        vol = im.numpy()\n",
        "        resampled_size = vol.shape\n",
        "\n",
        "    else:\n",
        "\n",
        "        resampled_size = original_shape\n",
        "\n",
        "    return original_shape, crop_shape, coord1, coord2, resampled_size, original_resolution\n",
        "\n",
        "\n",
        "def build_net_CT(patch_size,resolution):\n",
        "\n",
        "    from monai.networks.layers import Norm\n",
        "\n",
        "    sizes, spacings = patch_size, resolution\n",
        "\n",
        "    strides, kernels = [], []\n",
        "\n",
        "    while True:\n",
        "        spacing_ratio = [sp / min(spacings) for sp in spacings]\n",
        "        stride = [2 if ratio <= 2 and size >= 8 else 1 for (ratio, size) in zip(spacing_ratio, sizes)]\n",
        "        kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
        "        if all(s == 1 for s in stride):\n",
        "            break\n",
        "        sizes = [i / j for i, j in zip(sizes, stride)]\n",
        "        spacings = [i * j for i, j in zip(spacings, stride)]\n",
        "        kernels.append(kernel)\n",
        "        strides.append(stride)\n",
        "    strides.insert(0, len(spacings) * [1])\n",
        "    kernels.append(len(spacings) * [3])\n",
        "\n",
        "    # # create Unet\n",
        "\n",
        "    nn_Unet = monai.networks.nets.DynUNet(\n",
        "        spatial_dims=3,\n",
        "        in_channels=1,\n",
        "        out_channels=1,\n",
        "        kernel_size=kernels,\n",
        "        strides=strides,\n",
        "        upsample_kernel_size=strides[1:],\n",
        "        res_block=True,\n",
        "    )\n",
        "\n",
        "    return nn_Unet\n",
        "\n",
        "\n",
        "def crop_window(prostate_contour):\n",
        "    # Cut data, restricted to the prostate contours + a pitch per direction per dimension.\n",
        "    \"\"\"\n",
        "    nrrd has the following format, assuming to watch the patient from the front:\n",
        "    (x, y, z)\n",
        "    x: left to right (ascending)\n",
        "    y: front to back (ascending)\n",
        "    z: bottom to top (ascending)\n",
        "    \"\"\"\n",
        "    pitch = 5\n",
        "    pattern = np.where(prostate_contour == 1)\n",
        "\n",
        "    minx = np.min(pattern[0]) - pitch\n",
        "    maxx = np.max(pattern[0]) + pitch\n",
        "    miny = np.min(pattern[1]) - pitch\n",
        "    maxy = np.max(pattern[1]) + pitch\n",
        "    minz = np.min(pattern[2]) - pitch\n",
        "    maxz = np.max(pattern[2]) + pitch\n",
        "\n",
        "    if (maxx - minx) % 2 != 0:\n",
        "        maxx += 1\n",
        "    if (maxy - miny) % 2 != 0:\n",
        "        maxy += 1\n",
        "    if (maxz - minz) % 2 != 0:\n",
        "        maxz += 1\n",
        "\n",
        "    \"\"\"\n",
        "    Choose all tensors to have size of 64x64x64\n",
        "    \"\"\"\n",
        "    limit = 32\n",
        "\n",
        "    while maxx - minx < limit:\n",
        "        maxx += 1\n",
        "        minx -= 1\n",
        "\n",
        "    while maxy - miny < limit:\n",
        "        maxy += 1\n",
        "        miny -= 1\n",
        "\n",
        "    while maxz - minz < limit:\n",
        "        maxz += 1\n",
        "        minz -= 1\n",
        "\n",
        "    return minx, maxx, miny, maxy, minz, maxz\n",
        "\n",
        "\n",
        "def uniform_img_dimensions(image, label, nearest):\n",
        "\n",
        "    image_array = sitk.GetArrayFromImage(image)\n",
        "    image_array = np.transpose(image_array, axes=(2, 1, 0))  # reshape array from itk z,y,x  to  x,y,z\n",
        "    image_shape = image_array.shape\n",
        "\n",
        "    if nearest is True:\n",
        "        label = resample_sitk_image(label, spacing=image.GetSpacing(), interpolator='nearest')\n",
        "        res = resize(label,image_shape,sitk.sitkNearestNeighbor)\n",
        "        res = (np.rint(sitk.GetArrayFromImage(res)))\n",
        "        res = sitk.GetImageFromArray(res.astype('uint8'))\n",
        "        # print(res.GetSize())\n",
        "\n",
        "    else:\n",
        "        label = resample_sitk_image(label, spacing=image.GetSpacing(), interpolator='linear')\n",
        "        res = resize(label, image_shape, sitk.sitkLinear)\n",
        "        res = (np.rint(sitk.GetArrayFromImage(res)))\n",
        "        res = sitk.GetImageFromArray(res.astype('float'))\n",
        "\n",
        "    res.SetDirection(image.GetDirection())\n",
        "    res.SetOrigin(image.GetOrigin())\n",
        "    res.SetSpacing(image.GetSpacing())\n",
        "\n",
        "    return image, res\n",
        "\n",
        "\n",
        "def uniform_img_dimensions_internal(image, label, nearest):\n",
        "\n",
        "    name_label = label\n",
        "\n",
        "    image = sitk.ReadImage(image)\n",
        "    label = sitk.ReadImage(label)\n",
        "    image_array = sitk.GetArrayFromImage(image)\n",
        "    image_array = np.transpose(image_array, axes=(2, 1, 0))  # reshape array from itk z,y,x  to  x,y,z\n",
        "    image_shape = image_array.shape\n",
        "\n",
        "    if nearest is True:\n",
        "        label = resample_sitk_image(label, spacing=image.GetSpacing(), interpolator='nearest')\n",
        "        res = resize(label,image_shape,sitk.sitkNearestNeighbor)\n",
        "        res = (np.rint(sitk.GetArrayFromImage(res)))\n",
        "        res = sitk.GetImageFromArray(res.astype('uint8'))\n",
        "        # print(res.GetSize())\n",
        "\n",
        "    else:\n",
        "        label = resample_sitk_image(label, spacing=image.GetSpacing(), interpolator='linear')\n",
        "        res = resize(label, image_shape, sitk.sitkLinear)\n",
        "        res = (np.rint(sitk.GetArrayFromImage(res)))\n",
        "        res = sitk.GetImageFromArray(res.astype('float'))\n",
        "\n",
        "    res.SetDirection(image.GetDirection())\n",
        "    res.SetOrigin(image.GetOrigin())\n",
        "    res.SetSpacing(image.GetSpacing())\n",
        "\n",
        "    sitk.WriteImage(res, name_label)\n",
        "\n",
        "\n",
        "def normalize_PET(image_itk, value):\n",
        "\n",
        "    # read image file\n",
        "    image_np = sitk.GetArrayFromImage(image_itk)\n",
        "    image_np = image_np/value\n",
        "    image = sitk.GetImageFromArray(image_np)\n",
        "    image.SetDirection(image_itk.GetDirection())\n",
        "    image.SetSpacing(image_itk.GetSpacing())\n",
        "    image.SetOrigin(image_itk.GetOrigin())\n",
        "    return image\n",
        "\n",
        "\n",
        "def processing_itk(label_CT, image_PET, label_PET, gluteus, new_resolution, patch_size):\n",
        "\n",
        "    gluteus = sitk.ReadImage(gluteus)\n",
        "    label_CT = sitk.ReadImage(label_CT)\n",
        "    image_PET = sitk.ReadImage(image_PET)\n",
        "\n",
        "    if label_PET is not None:\n",
        "        label_PET = sitk.ReadImage(label_PET)\n",
        "\n",
        "    if new_resolution is not None:\n",
        "        image_PET = resample_sitk_image(image_PET, spacing=new_resolution, interpolator='linear')\n",
        "\n",
        "    label_CT = Padding(label_CT, image_PET)\n",
        "    gluteus = Padding(gluteus, image_PET)\n",
        "    image_PET, label_CT = uniform_img_dimensions(image_PET, label_CT, True)\n",
        "    image_PET, gluteus = uniform_img_dimensions(image_PET, gluteus, True)\n",
        "\n",
        "    # new part for Pet tumor_background normalization\n",
        "\n",
        "    gluteos_ROI_array = sitk.GetArrayFromImage(gluteus)\n",
        "    gluteos_ROI_index = np.where(gluteos_ROI_array == 1)\n",
        "    PET_array = sitk.GetArrayFromImage(image_PET)\n",
        "    avg = np.mean(PET_array[gluteos_ROI_index])\n",
        "    image_PET = normalize_PET(image_PET, avg)\n",
        "\n",
        "    # end normalization\n",
        "\n",
        "    if label_PET is not None:\n",
        "        label_PET = Padding(label_PET, image_PET)\n",
        "        image_PET, label_PET = uniform_img_dimensions(image_PET, label_PET, True)\n",
        "\n",
        "    label_CT_array = sitk.GetArrayFromImage(label_CT)\n",
        "\n",
        "    minx, maxx, miny, maxy, minz, maxz = crop_window(label_CT_array)\n",
        "\n",
        "    roiFilter = sitk.RegionOfInterestImageFilter()\n",
        "    roiFilter.SetSize(patch_size)\n",
        "    roiFilter.SetIndex([int(minz), int(miny), int(minx)])\n",
        "\n",
        "    label_CT = roiFilter.Execute(label_CT)\n",
        "    image_PET = roiFilter.Execute(image_PET)\n",
        "\n",
        "    if label_PET is not None:\n",
        "        label_PET = roiFilter.Execute(label_PET)\n",
        "    else:\n",
        "        label_PET = None\n",
        "\n",
        "    sitk.WriteImage(label_CT, 'mask_crop.nii')\n",
        "    sitk.WriteImage(image_PET, 'result.nii')\n",
        "\n",
        "    if label_PET is not None:\n",
        "\n",
        "        sitk.WriteImage(label_PET, 'label_crop.nii')\n",
        "\n",
        "\n",
        "def gaussian2(image):\n",
        "\n",
        "    resacleFilter = sitk.RescaleIntensityImageFilter()\n",
        "    resacleFilter.SetOutputMaximum(255)\n",
        "    resacleFilter.SetOutputMinimum(0)\n",
        "    image = resacleFilter.Execute(image)  # set intensity 0-255\n",
        "\n",
        "    gaussianFilter = sitk.SmoothingRecursiveGaussianImageFilter()\n",
        "    gaussianFilter.SetSigma(3)\n",
        "    image = gaussianFilter.Execute(image)\n",
        "\n",
        "    resacleFilter = sitk.RescaleIntensityImageFilter()\n",
        "    resacleFilter.SetOutputMaximum(1)\n",
        "    resacleFilter.SetOutputMinimum(0)\n",
        "    image = resacleFilter.Execute(image)  # set intensity 0-255\n",
        "\n",
        "    thresholdFilter = sitk.BinaryThresholdImageFilter()\n",
        "    thresholdFilter.SetLowerThreshold(0.5)\n",
        "    thresholdFilter.SetUpperThreshold(2)\n",
        "    thresholdFilter.SetInsideValue(1)\n",
        "    thresholdFilter.SetOutsideValue(0)\n",
        "    image = thresholdFilter.Execute(image)\n",
        "\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMKPBpiQX4jS"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "\n",
        "class Options():\n",
        "\n",
        "    \"\"\"This class defines options used during both training and test time.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"\n",
        "        self.initialized = False\n",
        "\n",
        "    def initialize(self, parser):\n",
        "\n",
        "        # basic parameters\n",
        "        parser.add_argument('--images_folder', type=str, default='/content/drive/My Drive/Data_folder/images')\n",
        "        parser.add_argument('--labels_folder', type=str, default='/content/drive/My Drive/Data_folder/labels')\n",
        "        parser.add_argument('--increase_factor_data',  default=1, help='Increase data number per epoch')\n",
        "        parser.add_argument('--preload', type=str, default=None)\n",
        "        parser.add_argument('--gpu_ids', type=str, default='0,1', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
        "        parser.add_argument('--workers', default=8, type=int, help='number of data loading workers')\n",
        "\n",
        "        # dataset parameters\n",
        "        parser.add_argument('--patch_size', default=(160, 160, 32), help='Size of the patches extracted from the image')\n",
        "        parser.add_argument('--spacing', default=[2.25, 2.25, 3], help='Original Resolution')\n",
        "        parser.add_argument('--resolution', default=None, help='New Resolution, if you want to resample the data in training. I suggest to resample in organize_folder_structure.py, otherwise in train resampling is slower')\n",
        "        parser.add_argument('--batch_size', type=int, default=4, help='batch size, depends on your machine')\n",
        "        parser.add_argument('--in_channels', default=1, type=int, help='Channels of the input')\n",
        "        parser.add_argument('--out_channels', default=1, type=int, help='Channels of the output')\n",
        "\n",
        "        # training parameters\n",
        "        parser.add_argument('--epochs', default=1000, help='Number of epochs')\n",
        "        parser.add_argument('--lr', default=0.01, help='Learning rate')\n",
        "\n",
        "        self.initialized = True\n",
        "        return parser\n",
        "\n",
        "    def parse(self):\n",
        "        if not self.initialized:\n",
        "            parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "            parser = self.initialize(parser)\n",
        "        opt = parser.parse_args()\n",
        "        # set gpu ids\n",
        "        if opt.gpu_ids != '-1':\n",
        "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = opt.gpu_ids\n",
        "        return opt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "SK5MHXNuX_Mk",
        "outputId": "92aa9486-4fe8-4e1f-c4f3-a5572fd85a58"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import argparse\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import random\n",
        "from utils import *\n",
        "import sys\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--images', default='/content/drive/My Drive/Data_folder/CT', help='path to the images')\n",
        "    parser.add_argument('--labels', default='/content/drive/My Drive/Data_folder/CT_label', help='path to the labels')\n",
        "    parser.add_argument('--split_val', default=30, help='number of images for validation')\n",
        "    parser.add_argument('--split_test', default=30, help='number of images for testing')\n",
        "    parser.add_argument('--resolution', default=[2.25, 2.25, 3], help='New Resolution to resample the data to same spacing')\n",
        "    parser.add_argument('--smooth', default=False, help='Set True if you want to smooth a bit the binary mask')\n",
        "    parser.add_argument('-f')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    list_images = lstFiles(args.images)\n",
        "    list_labels = lstFiles(args.labels)\n",
        "\n",
        "    mapIndexPosition = list(zip(list_images, list_labels))  \n",
        "# shuffle order list\n",
        "    random.shuffle(mapIndexPosition)\n",
        "    list_images, list_labels = zip(*mapIndexPosition)\n",
        "\n",
        "    os.mkdir('/content/drive/My Drive/Data_folder/images')\n",
        "    os.mkdir('/content/drive/My Drive/Data_folder/labels')\n",
        "\n",
        "    # 1\n",
        "    if not os.path.isdir('/content/drive/My Drive/Data_folder/images/train'):\n",
        "         os.mkdir('/content/drive/My Drive/Data_folder/images/train/')\n",
        "    # 2\n",
        "    if not os.path.isdir('/content/drive/My Drive/Data_folder/images/val'):\n",
        "        os.mkdir('/content/drive/My Drive/Data_folder/images/val')\n",
        "\n",
        "    # 3\n",
        "    if not os.path.isdir('/content/drive/My Drive/Data_folder/images/test'):\n",
        "        os.mkdir('/content/drive/My Drive/Data_folder/images/test')\n",
        "\n",
        "    # 4\n",
        "    if not os.path.isdir('/content/drive/My Drive/Data_folder/labels/train'):\n",
        "        os.mkdir('/content/drive/My Drive/Data_folder/labels/train')\n",
        "\n",
        "    # 5\n",
        "    if not os.path.isdir('/content/drive/My Drive/Data_folder/labels/val'):\n",
        "        os.mkdir('/content/drive/My Drive/Data_folder/labels/val')\n",
        "\n",
        "    # 6\n",
        "    if not os.path.isdir('/content/drive/My Drive/Data_folder/labels/test'):\n",
        "        os.mkdir('/content/drive/My Drive/Data_folder/labels/test')\n",
        "\n",
        "    for i in range(len(list_images)-int(args.split_test + args.split_val)):\n",
        "\n",
        "        a = list_images[int(args.split_test + args.split_val)+i]\n",
        "        b = list_labels[int(args.split_test + args.split_val)+i]\n",
        "\n",
        "        print('train',i, a,b)\n",
        "\n",
        "        label = sitk.ReadImage(b)\n",
        "        image = sitk.ReadImage(a)\n",
        "\n",
        "        image = resample_sitk_image(image, spacing=args.resolution, interpolator='linear', fill_value=0)\n",
        "        image, label = uniform_img_dimensions(image, label, nearest=True)\n",
        "        if args.smooth is True:\n",
        "            label = gaussian2(label)\n",
        "\n",
        "        image_directory = os.path.join('/content/drive/My Drive/Data_folder/images/train', -f\"image{i:d}.nii\")\n",
        "        label_directory = os.path.join('/content/drive/My Drive/Data_folder/labels/train', -f\"label{i:d}.nii\")\n",
        "\n",
        "        sitk.WriteImage(image, image_directory)\n",
        "        sitk.WriteImage(label, label_directory)\n",
        "\n",
        "     \n",
        "\n",
        "     \n",
        "        image = resample_sitk_image(image, spacing=args.resolution, interpolator='linear', fill_value=0)\n",
        "        image, label = uniform_img_dimensions(image, label, nearest=True)\n",
        "        if args.smooth is True:\n",
        "            label = gaussian2(label)\n",
        "\n",
        "        image_directory = os.path.join('/content/drive/My Drive/Data_folder/images/val', f\"image{i:d}.nii\")\n",
        "        label_directory = os.path.join('/content/drive/My Drive/Data_folder/labels/val', f\"label{i:d}.nii\")\n",
        "\n",
        "        sitk.WriteImage(image, image_directory)\n",
        "        sitk.WriteImage(label, label_directory)\n",
        "\n",
        "    for i in range(int(args.split_test)):\n",
        "\n",
        "        a = list_images[i]\n",
        "        b = list_labels[i]\n",
        "\n",
        "        print('test',i,a,b)\n",
        "\n",
        "        label = sitk.ReadImage(b)\n",
        "        image = sitk.ReadImage(a)\n",
        "\n",
        "        image = resample_sitk_image(image, spacing=args.resolution, interpolator='linear', fill_value=0)\n",
        "        image, label = uniform_img_dimensions(image, label, nearest=True)\n",
        "        if args.smooth is True:\n",
        "            label = gaussian2(label)\n",
        "\n",
        "        image_directory = os.path.join('/content/drive/My Drive/Data_folder/images/test', f\"image{i:d}.nii\")\n",
        "        label_directory = os.path.join('/content/drive/My Drive/Data_folder/labels/test', f\"label{i:d}.nii\")\n",
        "\n",
        "        sitk.WriteImage(image, image_directory)\n",
        "        sitk.WriteImage(label, label_directory)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-050cf810e7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlist_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmapIndexPosition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Data_folder/images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Data_folder/labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/My Drive/Data_folder/images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayT6NKVSLE0",
        "outputId": "4dd016cc-483a-4e93-d38b-24e45f41a3ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElimwKXvtBFh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDtWyN-TcxW2",
        "outputId": "30fba2e5-7afd-4831-d92e-6f987ec1b985"
      },
      "source": [
        "from train import *\n",
        "from torch.nn import init\n",
        "import monai\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "\n",
        "def init_weights(net, init_type='normal', init_gain=0.02):\n",
        "    \"\"\"Initialize network weights.\n",
        "    Parameters:\n",
        "        net (network)   -- network to be initialized\n",
        "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
        "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
        "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
        "    work better for some applications. Feel free to try yourself.\n",
        "    \"\"\"\n",
        "    def init_func(m):  # define the initialization function\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            elif init_type == 'orthogonal':\n",
        "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm3d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    # print('initialize network with %s' % init_type)\n",
        "    net.apply(init_func)  # apply the initialization function <init_func>\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer, opt):\n",
        "    if opt.lr_policy == 'lambda':\n",
        "        def lambda_rule(epoch):\n",
        "            # lr_l = 1.0 - max(0, epoch + 1 - opt.epochs/2) / float(opt.epochs/2 + 1)\n",
        "            lr_l = (1 - epoch / opt.epochs) ** 0.9\n",
        "            return lr_l\n",
        "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
        "    elif opt.lr_policy == 'step':\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
        "    elif opt.lr_policy == 'plateau':\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
        "    elif opt.lr_policy == 'cosine':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=opt.epochs, eta_min=0)\n",
        "    else:\n",
        "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "# update learning rate (called once every epoch)\n",
        "def update_learning_rate(scheduler, optimizer):\n",
        "    scheduler.step()\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    # print('learning rate = %.7f' % lr)\n",
        "\n",
        "\n",
        "from torch.nn import Module, Sequential\n",
        "from torch.nn import Conv3d, ConvTranspose3d, BatchNorm3d, MaxPool3d, AvgPool1d, Dropout3d\n",
        "from torch.nn import ReLU, Sigmoid\n",
        "import torch\n",
        "\n",
        "\n",
        "def build_net():\n",
        "\n",
        "    from init import Options\n",
        "    opt = Options().parse()\n",
        "    from monai.networks.layers import Norm\n",
        "\n",
        "    # create nn-Unet\n",
        "    if opt.resolution is None:\n",
        "        sizes, spacings = opt.patch_size, opt.spacing\n",
        "    else:\n",
        "        sizes, spacings = opt.patch_size, opt.resolution\n",
        "\n",
        "    strides, kernels = [], []\n",
        "\n",
        "    while True:\n",
        "        spacing_ratio = [sp / min(spacings) for sp in spacings]\n",
        "        stride = [2 if ratio <= 2 and size >= 8 else 1 for (ratio, size) in zip(spacing_ratio, sizes)]\n",
        "        kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
        "        if all(s == 1 for s in stride):\n",
        "            break\n",
        "        sizes = [i / j for i, j in zip(sizes, stride)]\n",
        "        spacings = [i * j for i, j in zip(spacings, stride)]\n",
        "        kernels.append(kernel)\n",
        "        strides.append(stride)\n",
        "    strides.insert(0, len(spacings) * [1])\n",
        "    kernels.append(len(spacings) * [3])\n",
        "\n",
        "    # # create Unet\n",
        "\n",
        "    nn_Unet = monai.networks.nets.DynUNet(\n",
        "        spatial_dims=3,\n",
        "        in_channels=opt.in_channels,\n",
        "        out_channels=opt.out_channels,\n",
        "        kernel_size=kernels,\n",
        "        strides=strides,\n",
        "        upsample_kernel_size=strides[1:],\n",
        "        res_block=True,\n",
        "    )\n",
        "\n",
        "    init_weights(nn_Unet, init_type='normal')\n",
        "\n",
        "    return nn_Unet\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import time\n",
        "    import torch\n",
        "    from torch.autograd import Variable\n",
        "    from torchsummaryX import summary\n",
        "    from torch.nn import init\n",
        "\n",
        "    opt = Options().parse()\n",
        "\n",
        "    torch.cuda.set_device(0)\n",
        "    network = build_net()\n",
        "    net = network.cuda().eval()\n",
        "\n",
        "    data = Variable(torch.randn(1, int(opt.in_channels), int(opt.patch_size[0]), int(opt.patch_size[1]), int(opt.patch_size[2]))).cuda()\n",
        "\n",
        "    out = net(data)\n",
        "\n",
        "    torch.onnx.export(net, data, \"Unet_model_graph.onnx\")\n",
        "\n",
        "    summary(net,data)\n",
        "    print(\"out size: {}\".format(out.size()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================================================================================================================================\n",
            "                                                           Kernel Shape  \\\n",
            "Layer                                                                     \n",
            "0_skip_layers.downsample.conv1.Conv3d_conv             [1, 32, 3, 3, 3]   \n",
            "1_skip_layers.downsample.conv1.Conv3d_conv             [1, 32, 3, 3, 3]   \n",
            "2_skip_layers.downsample.InstanceNorm3d_norm1                      [32]   \n",
            "3_skip_layers.downsample.InstanceNorm3d_norm1                      [32]   \n",
            "4_skip_layers.downsample.LeakyReLU_lrelu                              -   \n",
            "5_skip_layers.downsample.LeakyReLU_lrelu                              -   \n",
            "6_skip_layers.downsample.conv2.Conv3d_conv            [32, 32, 3, 3, 3]   \n",
            "7_skip_layers.downsample.conv2.Conv3d_conv            [32, 32, 3, 3, 3]   \n",
            "8_skip_layers.downsample.InstanceNorm3d_norm2                      [32]   \n",
            "9_skip_layers.downsample.InstanceNorm3d_norm2                      [32]   \n",
            "10_skip_layers.downsample.conv3.Conv3d_conv            [1, 32, 1, 1, 1]   \n",
            "11_skip_layers.downsample.conv3.Conv3d_conv            [1, 32, 1, 1, 1]   \n",
            "12_skip_layers.downsample.InstanceNorm3d_norm3                     [32]   \n",
            "13_skip_layers.downsample.InstanceNorm3d_norm3                     [32]   \n",
            "14_skip_layers.downsample.LeakyReLU_lrelu                             -   \n",
            "15_skip_layers.downsample.LeakyReLU_lrelu                             -   \n",
            "16_skip_layers.next_layer.downsample.conv1.Conv...    [32, 64, 3, 3, 3]   \n",
            "17_skip_layers.next_layer.downsample.conv1.Conv...    [32, 64, 3, 3, 3]   \n",
            "18_skip_layers.next_layer.downsample.InstanceNo...                 [64]   \n",
            "19_skip_layers.next_layer.downsample.InstanceNo...                 [64]   \n",
            "20_skip_layers.next_layer.downsample.LeakyReLU_...                    -   \n",
            "21_skip_layers.next_layer.downsample.LeakyReLU_...                    -   \n",
            "22_skip_layers.next_layer.downsample.conv2.Conv...    [64, 64, 3, 3, 3]   \n",
            "23_skip_layers.next_layer.downsample.conv2.Conv...    [64, 64, 3, 3, 3]   \n",
            "24_skip_layers.next_layer.downsample.InstanceNo...                 [64]   \n",
            "25_skip_layers.next_layer.downsample.InstanceNo...                 [64]   \n",
            "26_skip_layers.next_layer.downsample.conv3.Conv...    [32, 64, 1, 1, 1]   \n",
            "27_skip_layers.next_layer.downsample.conv3.Conv...    [32, 64, 1, 1, 1]   \n",
            "28_skip_layers.next_layer.downsample.InstanceNo...                 [64]   \n",
            "29_skip_layers.next_layer.downsample.InstanceNo...                 [64]   \n",
            "30_skip_layers.next_layer.downsample.LeakyReLU_...                    -   \n",
            "31_skip_layers.next_layer.downsample.LeakyReLU_...                    -   \n",
            "32_skip_layers.next_layer.next_layer.downsample...   [64, 128, 3, 3, 3]   \n",
            "33_skip_layers.next_layer.next_layer.downsample...   [64, 128, 3, 3, 3]   \n",
            "34_skip_layers.next_layer.next_layer.downsample...                [128]   \n",
            "35_skip_layers.next_layer.next_layer.downsample...                [128]   \n",
            "36_skip_layers.next_layer.next_layer.downsample...                    -   \n",
            "37_skip_layers.next_layer.next_layer.downsample...                    -   \n",
            "38_skip_layers.next_layer.next_layer.downsample...  [128, 128, 3, 3, 3]   \n",
            "39_skip_layers.next_layer.next_layer.downsample...  [128, 128, 3, 3, 3]   \n",
            "40_skip_layers.next_layer.next_layer.downsample...                [128]   \n",
            "41_skip_layers.next_layer.next_layer.downsample...                [128]   \n",
            "42_skip_layers.next_layer.next_layer.downsample...   [64, 128, 1, 1, 1]   \n",
            "43_skip_layers.next_layer.next_layer.downsample...   [64, 128, 1, 1, 1]   \n",
            "44_skip_layers.next_layer.next_layer.downsample...                [128]   \n",
            "45_skip_layers.next_layer.next_layer.downsample...                [128]   \n",
            "46_skip_layers.next_layer.next_layer.downsample...                    -   \n",
            "47_skip_layers.next_layer.next_layer.downsample...                    -   \n",
            "48_skip_layers.next_layer.next_layer.next_layer...  [128, 256, 3, 3, 3]   \n",
            "49_skip_layers.next_layer.next_layer.next_layer...  [128, 256, 3, 3, 3]   \n",
            "50_skip_layers.next_layer.next_layer.next_layer...                [256]   \n",
            "51_skip_layers.next_layer.next_layer.next_layer...                [256]   \n",
            "52_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "53_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "54_skip_layers.next_layer.next_layer.next_layer...  [256, 256, 3, 3, 3]   \n",
            "55_skip_layers.next_layer.next_layer.next_layer...  [256, 256, 3, 3, 3]   \n",
            "56_skip_layers.next_layer.next_layer.next_layer...                [256]   \n",
            "57_skip_layers.next_layer.next_layer.next_layer...                [256]   \n",
            "58_skip_layers.next_layer.next_layer.next_layer...  [128, 256, 1, 1, 1]   \n",
            "59_skip_layers.next_layer.next_layer.next_layer...  [128, 256, 1, 1, 1]   \n",
            "60_skip_layers.next_layer.next_layer.next_layer...                [256]   \n",
            "61_skip_layers.next_layer.next_layer.next_layer...                [256]   \n",
            "62_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "63_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "64_skip_layers.next_layer.next_layer.next_layer...  [256, 320, 3, 3, 3]   \n",
            "65_skip_layers.next_layer.next_layer.next_layer...  [256, 320, 3, 3, 3]   \n",
            "66_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "67_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "68_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "69_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "70_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 3, 3, 3]   \n",
            "71_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 3, 3, 3]   \n",
            "72_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "73_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "74_skip_layers.next_layer.next_layer.next_layer...  [256, 320, 1, 1, 1]   \n",
            "75_skip_layers.next_layer.next_layer.next_layer...  [256, 320, 1, 1, 1]   \n",
            "76_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "77_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "78_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "79_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "80_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 3, 3, 3]   \n",
            "81_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 3, 3, 3]   \n",
            "82_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "83_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "84_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "85_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "86_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 3, 3, 3]   \n",
            "87_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 3, 3, 3]   \n",
            "88_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "89_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "90_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 1, 1, 1]   \n",
            "91_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 1, 1, 1]   \n",
            "92_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "93_skip_layers.next_layer.next_layer.next_layer...                [320]   \n",
            "94_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "95_skip_layers.next_layer.next_layer.next_layer...                    -   \n",
            "96_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 2, 2, 1]   \n",
            "97_skip_layers.next_layer.next_layer.next_layer...  [320, 320, 2, 2, 1]   \n",
            "98_skip_layers.next_layer.next_layer.next_layer...  [640, 320, 3, 3, 3]   \n",
            "99_skip_layers.next_layer.next_layer.next_layer...  [640, 320, 3, 3, 3]   \n",
            "100_skip_layers.next_layer.next_layer.next_laye...                [320]   \n",
            "101_skip_layers.next_layer.next_layer.next_laye...                [320]   \n",
            "102_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "103_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "104_skip_layers.next_layer.next_layer.next_laye...  [320, 320, 3, 3, 3]   \n",
            "105_skip_layers.next_layer.next_layer.next_laye...  [320, 320, 3, 3, 3]   \n",
            "106_skip_layers.next_layer.next_layer.next_laye...                [320]   \n",
            "107_skip_layers.next_layer.next_layer.next_laye...                [320]   \n",
            "108_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "109_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "110_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "111_skip_layers.next_layer.next_layer.next_laye...  [256, 320, 2, 2, 1]   \n",
            "112_skip_layers.next_layer.next_layer.next_laye...  [256, 320, 2, 2, 1]   \n",
            "113_skip_layers.next_layer.next_layer.next_laye...  [512, 256, 3, 3, 3]   \n",
            "114_skip_layers.next_layer.next_layer.next_laye...  [512, 256, 3, 3, 3]   \n",
            "115_skip_layers.next_layer.next_layer.next_laye...                [256]   \n",
            "116_skip_layers.next_layer.next_layer.next_laye...                [256]   \n",
            "117_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "118_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "119_skip_layers.next_layer.next_layer.next_laye...  [256, 256, 3, 3, 3]   \n",
            "120_skip_layers.next_layer.next_layer.next_laye...  [256, 256, 3, 3, 3]   \n",
            "121_skip_layers.next_layer.next_layer.next_laye...                [256]   \n",
            "122_skip_layers.next_layer.next_layer.next_laye...                [256]   \n",
            "123_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "124_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "125_skip_layers.next_layer.next_layer.next_laye...                    -   \n",
            "126_skip_layers.next_layer.next_layer.upsample....  [128, 256, 2, 2, 2]   \n",
            "127_skip_layers.next_layer.next_layer.upsample....  [128, 256, 2, 2, 2]   \n",
            "128_skip_layers.next_layer.next_layer.upsample....  [256, 128, 3, 3, 3]   \n",
            "129_skip_layers.next_layer.next_layer.upsample....  [256, 128, 3, 3, 3]   \n",
            "130_skip_layers.next_layer.next_layer.upsample....                [128]   \n",
            "131_skip_layers.next_layer.next_layer.upsample....                [128]   \n",
            "132_skip_layers.next_layer.next_layer.upsample....                    -   \n",
            "133_skip_layers.next_layer.next_layer.upsample....                    -   \n",
            "134_skip_layers.next_layer.next_layer.upsample....  [128, 128, 3, 3, 3]   \n",
            "135_skip_layers.next_layer.next_layer.upsample....  [128, 128, 3, 3, 3]   \n",
            "136_skip_layers.next_layer.next_layer.upsample....                [128]   \n",
            "137_skip_layers.next_layer.next_layer.upsample....                [128]   \n",
            "138_skip_layers.next_layer.next_layer.upsample....                    -   \n",
            "139_skip_layers.next_layer.next_layer.upsample....                    -   \n",
            "140_skip_layers.next_layer.next_layer.Identity_...                    -   \n",
            "141_skip_layers.next_layer.upsample.transp_conv...   [64, 128, 2, 2, 2]   \n",
            "142_skip_layers.next_layer.upsample.transp_conv...   [64, 128, 2, 2, 2]   \n",
            "143_skip_layers.next_layer.upsample.conv_block....   [128, 64, 3, 3, 3]   \n",
            "144_skip_layers.next_layer.upsample.conv_block....   [128, 64, 3, 3, 3]   \n",
            "145_skip_layers.next_layer.upsample.conv_block....                 [64]   \n",
            "146_skip_layers.next_layer.upsample.conv_block....                 [64]   \n",
            "147_skip_layers.next_layer.upsample.conv_block....                    -   \n",
            "148_skip_layers.next_layer.upsample.conv_block....                    -   \n",
            "149_skip_layers.next_layer.upsample.conv_block....    [64, 64, 3, 3, 3]   \n",
            "150_skip_layers.next_layer.upsample.conv_block....    [64, 64, 3, 3, 3]   \n",
            "151_skip_layers.next_layer.upsample.conv_block....                 [64]   \n",
            "152_skip_layers.next_layer.upsample.conv_block....                 [64]   \n",
            "153_skip_layers.next_layer.upsample.conv_block....                    -   \n",
            "154_skip_layers.next_layer.upsample.conv_block....                    -   \n",
            "155_skip_layers.next_layer.Identity_super_head                        -   \n",
            "156_skip_layers.upsample.transp_conv.ConvTransp...    [32, 64, 2, 2, 2]   \n",
            "157_skip_layers.upsample.transp_conv.ConvTransp...    [32, 64, 2, 2, 2]   \n",
            "158_skip_layers.upsample.conv_block.conv1.Conv3...    [64, 32, 3, 3, 3]   \n",
            "159_skip_layers.upsample.conv_block.conv1.Conv3...    [64, 32, 3, 3, 3]   \n",
            "160_skip_layers.upsample.conv_block.InstanceNor...                 [32]   \n",
            "161_skip_layers.upsample.conv_block.InstanceNor...                 [32]   \n",
            "162_skip_layers.upsample.conv_block.LeakyReLU_l...                    -   \n",
            "163_skip_layers.upsample.conv_block.LeakyReLU_l...                    -   \n",
            "164_skip_layers.upsample.conv_block.conv2.Conv3...    [32, 32, 3, 3, 3]   \n",
            "165_skip_layers.upsample.conv_block.conv2.Conv3...    [32, 32, 3, 3, 3]   \n",
            "166_skip_layers.upsample.conv_block.InstanceNor...                 [32]   \n",
            "167_skip_layers.upsample.conv_block.InstanceNor...                 [32]   \n",
            "168_skip_layers.upsample.conv_block.LeakyReLU_l...                    -   \n",
            "169_skip_layers.upsample.conv_block.LeakyReLU_l...                    -   \n",
            "170_skip_layers.Identity_super_head                                   -   \n",
            "171_output_block.conv.Conv3d_conv                      [32, 1, 1, 1, 1]   \n",
            "\n",
            "                                                             Output Shape  \\\n",
            "Layer                                                                       \n",
            "0_skip_layers.downsample.conv1.Conv3d_conv          [1, 32, 160, 160, 32]   \n",
            "1_skip_layers.downsample.conv1.Conv3d_conv          [1, 32, 160, 160, 32]   \n",
            "2_skip_layers.downsample.InstanceNorm3d_norm1       [1, 32, 160, 160, 32]   \n",
            "3_skip_layers.downsample.InstanceNorm3d_norm1       [1, 32, 160, 160, 32]   \n",
            "4_skip_layers.downsample.LeakyReLU_lrelu            [1, 32, 160, 160, 32]   \n",
            "5_skip_layers.downsample.LeakyReLU_lrelu            [1, 32, 160, 160, 32]   \n",
            "6_skip_layers.downsample.conv2.Conv3d_conv          [1, 32, 160, 160, 32]   \n",
            "7_skip_layers.downsample.conv2.Conv3d_conv          [1, 32, 160, 160, 32]   \n",
            "8_skip_layers.downsample.InstanceNorm3d_norm2       [1, 32, 160, 160, 32]   \n",
            "9_skip_layers.downsample.InstanceNorm3d_norm2       [1, 32, 160, 160, 32]   \n",
            "10_skip_layers.downsample.conv3.Conv3d_conv         [1, 32, 160, 160, 32]   \n",
            "11_skip_layers.downsample.conv3.Conv3d_conv         [1, 32, 160, 160, 32]   \n",
            "12_skip_layers.downsample.InstanceNorm3d_norm3      [1, 32, 160, 160, 32]   \n",
            "13_skip_layers.downsample.InstanceNorm3d_norm3      [1, 32, 160, 160, 32]   \n",
            "14_skip_layers.downsample.LeakyReLU_lrelu           [1, 32, 160, 160, 32]   \n",
            "15_skip_layers.downsample.LeakyReLU_lrelu           [1, 32, 160, 160, 32]   \n",
            "16_skip_layers.next_layer.downsample.conv1.Conv...    [1, 64, 80, 80, 16]   \n",
            "17_skip_layers.next_layer.downsample.conv1.Conv...    [1, 64, 80, 80, 16]   \n",
            "18_skip_layers.next_layer.downsample.InstanceNo...    [1, 64, 80, 80, 16]   \n",
            "19_skip_layers.next_layer.downsample.InstanceNo...    [1, 64, 80, 80, 16]   \n",
            "20_skip_layers.next_layer.downsample.LeakyReLU_...    [1, 64, 80, 80, 16]   \n",
            "21_skip_layers.next_layer.downsample.LeakyReLU_...    [1, 64, 80, 80, 16]   \n",
            "22_skip_layers.next_layer.downsample.conv2.Conv...    [1, 64, 80, 80, 16]   \n",
            "23_skip_layers.next_layer.downsample.conv2.Conv...    [1, 64, 80, 80, 16]   \n",
            "24_skip_layers.next_layer.downsample.InstanceNo...    [1, 64, 80, 80, 16]   \n",
            "25_skip_layers.next_layer.downsample.InstanceNo...    [1, 64, 80, 80, 16]   \n",
            "26_skip_layers.next_layer.downsample.conv3.Conv...    [1, 64, 80, 80, 16]   \n",
            "27_skip_layers.next_layer.downsample.conv3.Conv...    [1, 64, 80, 80, 16]   \n",
            "28_skip_layers.next_layer.downsample.InstanceNo...    [1, 64, 80, 80, 16]   \n",
            "29_skip_layers.next_layer.downsample.InstanceNo...    [1, 64, 80, 80, 16]   \n",
            "30_skip_layers.next_layer.downsample.LeakyReLU_...    [1, 64, 80, 80, 16]   \n",
            "31_skip_layers.next_layer.downsample.LeakyReLU_...    [1, 64, 80, 80, 16]   \n",
            "32_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "33_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "34_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "35_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "36_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "37_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "38_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "39_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "40_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "41_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "42_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "43_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "44_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "45_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "46_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "47_skip_layers.next_layer.next_layer.downsample...    [1, 128, 40, 40, 8]   \n",
            "48_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "49_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "50_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "51_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "52_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "53_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "54_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "55_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "56_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "57_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "58_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "59_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "60_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "61_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "62_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "63_skip_layers.next_layer.next_layer.next_layer...    [1, 256, 20, 20, 4]   \n",
            "64_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "65_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "66_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "67_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "68_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "69_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "70_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "71_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "72_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "73_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "74_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "75_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "76_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "77_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "78_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "79_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "80_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "81_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "82_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "83_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "84_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "85_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "86_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "87_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "88_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "89_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "90_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "91_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "92_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "93_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "94_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "95_skip_layers.next_layer.next_layer.next_layer...      [1, 320, 5, 5, 4]   \n",
            "96_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "97_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "98_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "99_skip_layers.next_layer.next_layer.next_layer...    [1, 320, 10, 10, 4]   \n",
            "100_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "101_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "102_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "103_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "104_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "105_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "106_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "107_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "108_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "109_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "110_skip_layers.next_layer.next_layer.next_laye...    [1, 320, 10, 10, 4]   \n",
            "111_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "112_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "113_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "114_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "115_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "116_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "117_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "118_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "119_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "120_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "121_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "122_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "123_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "124_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "125_skip_layers.next_layer.next_layer.next_laye...    [1, 256, 20, 20, 4]   \n",
            "126_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "127_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "128_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "129_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "130_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "131_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "132_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "133_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "134_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "135_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "136_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "137_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "138_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "139_skip_layers.next_layer.next_layer.upsample....    [1, 128, 40, 40, 8]   \n",
            "140_skip_layers.next_layer.next_layer.Identity_...    [1, 128, 40, 40, 8]   \n",
            "141_skip_layers.next_layer.upsample.transp_conv...    [1, 64, 80, 80, 16]   \n",
            "142_skip_layers.next_layer.upsample.transp_conv...    [1, 64, 80, 80, 16]   \n",
            "143_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "144_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "145_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "146_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "147_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "148_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "149_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "150_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "151_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "152_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "153_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "154_skip_layers.next_layer.upsample.conv_block....    [1, 64, 80, 80, 16]   \n",
            "155_skip_layers.next_layer.Identity_super_head        [1, 64, 80, 80, 16]   \n",
            "156_skip_layers.upsample.transp_conv.ConvTransp...  [1, 32, 160, 160, 32]   \n",
            "157_skip_layers.upsample.transp_conv.ConvTransp...  [1, 32, 160, 160, 32]   \n",
            "158_skip_layers.upsample.conv_block.conv1.Conv3...  [1, 32, 160, 160, 32]   \n",
            "159_skip_layers.upsample.conv_block.conv1.Conv3...  [1, 32, 160, 160, 32]   \n",
            "160_skip_layers.upsample.conv_block.InstanceNor...  [1, 32, 160, 160, 32]   \n",
            "161_skip_layers.upsample.conv_block.InstanceNor...  [1, 32, 160, 160, 32]   \n",
            "162_skip_layers.upsample.conv_block.LeakyReLU_l...  [1, 32, 160, 160, 32]   \n",
            "163_skip_layers.upsample.conv_block.LeakyReLU_l...  [1, 32, 160, 160, 32]   \n",
            "164_skip_layers.upsample.conv_block.conv2.Conv3...  [1, 32, 160, 160, 32]   \n",
            "165_skip_layers.upsample.conv_block.conv2.Conv3...  [1, 32, 160, 160, 32]   \n",
            "166_skip_layers.upsample.conv_block.InstanceNor...  [1, 32, 160, 160, 32]   \n",
            "167_skip_layers.upsample.conv_block.InstanceNor...  [1, 32, 160, 160, 32]   \n",
            "168_skip_layers.upsample.conv_block.LeakyReLU_l...  [1, 32, 160, 160, 32]   \n",
            "169_skip_layers.upsample.conv_block.LeakyReLU_l...  [1, 32, 160, 160, 32]   \n",
            "170_skip_layers.Identity_super_head                 [1, 32, 160, 160, 32]   \n",
            "171_output_block.conv.Conv3d_conv                    [1, 1, 160, 160, 32]   \n",
            "\n",
            "                                                       Params    Mult-Adds  \n",
            "Layer                                                                       \n",
            "0_skip_layers.downsample.conv1.Conv3d_conv              864.0    707.7888M  \n",
            "1_skip_layers.downsample.conv1.Conv3d_conv                  -    707.7888M  \n",
            "2_skip_layers.downsample.InstanceNorm3d_norm1            64.0         32.0  \n",
            "3_skip_layers.downsample.InstanceNorm3d_norm1               -         32.0  \n",
            "4_skip_layers.downsample.LeakyReLU_lrelu                    -            -  \n",
            "5_skip_layers.downsample.LeakyReLU_lrelu                    -            -  \n",
            "6_skip_layers.downsample.conv2.Conv3d_conv            27.648k  22.6492416G  \n",
            "7_skip_layers.downsample.conv2.Conv3d_conv                  -  22.6492416G  \n",
            "8_skip_layers.downsample.InstanceNorm3d_norm2            64.0         32.0  \n",
            "9_skip_layers.downsample.InstanceNorm3d_norm2               -         32.0  \n",
            "10_skip_layers.downsample.conv3.Conv3d_conv              32.0     26.2144M  \n",
            "11_skip_layers.downsample.conv3.Conv3d_conv                 -     26.2144M  \n",
            "12_skip_layers.downsample.InstanceNorm3d_norm3           64.0         32.0  \n",
            "13_skip_layers.downsample.InstanceNorm3d_norm3              -         32.0  \n",
            "14_skip_layers.downsample.LeakyReLU_lrelu                   -            -  \n",
            "15_skip_layers.downsample.LeakyReLU_lrelu                   -            -  \n",
            "16_skip_layers.next_layer.downsample.conv1.Conv...    55.296k   5.6623104G  \n",
            "17_skip_layers.next_layer.downsample.conv1.Conv...          -   5.6623104G  \n",
            "18_skip_layers.next_layer.downsample.InstanceNo...      128.0         64.0  \n",
            "19_skip_layers.next_layer.downsample.InstanceNo...          -         64.0  \n",
            "20_skip_layers.next_layer.downsample.LeakyReLU_...          -            -  \n",
            "21_skip_layers.next_layer.downsample.LeakyReLU_...          -            -  \n",
            "22_skip_layers.next_layer.downsample.conv2.Conv...   110.592k  11.3246208G  \n",
            "23_skip_layers.next_layer.downsample.conv2.Conv...          -  11.3246208G  \n",
            "24_skip_layers.next_layer.downsample.InstanceNo...      128.0         64.0  \n",
            "25_skip_layers.next_layer.downsample.InstanceNo...          -         64.0  \n",
            "26_skip_layers.next_layer.downsample.conv3.Conv...     2.048k    209.7152M  \n",
            "27_skip_layers.next_layer.downsample.conv3.Conv...          -    209.7152M  \n",
            "28_skip_layers.next_layer.downsample.InstanceNo...      128.0         64.0  \n",
            "29_skip_layers.next_layer.downsample.InstanceNo...          -         64.0  \n",
            "30_skip_layers.next_layer.downsample.LeakyReLU_...          -            -  \n",
            "31_skip_layers.next_layer.downsample.LeakyReLU_...          -            -  \n",
            "32_skip_layers.next_layer.next_layer.downsample...   221.184k   2.8311552G  \n",
            "33_skip_layers.next_layer.next_layer.downsample...          -   2.8311552G  \n",
            "34_skip_layers.next_layer.next_layer.downsample...      256.0        128.0  \n",
            "35_skip_layers.next_layer.next_layer.downsample...          -        128.0  \n",
            "36_skip_layers.next_layer.next_layer.downsample...          -            -  \n",
            "37_skip_layers.next_layer.next_layer.downsample...          -            -  \n",
            "38_skip_layers.next_layer.next_layer.downsample...   442.368k   5.6623104G  \n",
            "39_skip_layers.next_layer.next_layer.downsample...          -   5.6623104G  \n",
            "40_skip_layers.next_layer.next_layer.downsample...      256.0        128.0  \n",
            "41_skip_layers.next_layer.next_layer.downsample...          -        128.0  \n",
            "42_skip_layers.next_layer.next_layer.downsample...     8.192k    104.8576M  \n",
            "43_skip_layers.next_layer.next_layer.downsample...          -    104.8576M  \n",
            "44_skip_layers.next_layer.next_layer.downsample...      256.0        128.0  \n",
            "45_skip_layers.next_layer.next_layer.downsample...          -        128.0  \n",
            "46_skip_layers.next_layer.next_layer.downsample...          -            -  \n",
            "47_skip_layers.next_layer.next_layer.downsample...          -            -  \n",
            "48_skip_layers.next_layer.next_layer.next_layer...   884.736k   1.4155776G  \n",
            "49_skip_layers.next_layer.next_layer.next_layer...          -   1.4155776G  \n",
            "50_skip_layers.next_layer.next_layer.next_layer...      512.0        256.0  \n",
            "51_skip_layers.next_layer.next_layer.next_layer...          -        256.0  \n",
            "52_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "53_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "54_skip_layers.next_layer.next_layer.next_layer...  1.769472M   2.8311552G  \n",
            "55_skip_layers.next_layer.next_layer.next_layer...          -   2.8311552G  \n",
            "56_skip_layers.next_layer.next_layer.next_layer...      512.0        256.0  \n",
            "57_skip_layers.next_layer.next_layer.next_layer...          -        256.0  \n",
            "58_skip_layers.next_layer.next_layer.next_layer...    32.768k     52.4288M  \n",
            "59_skip_layers.next_layer.next_layer.next_layer...          -     52.4288M  \n",
            "60_skip_layers.next_layer.next_layer.next_layer...      512.0        256.0  \n",
            "61_skip_layers.next_layer.next_layer.next_layer...          -        256.0  \n",
            "62_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "63_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "64_skip_layers.next_layer.next_layer.next_layer...   2.21184M     884.736M  \n",
            "65_skip_layers.next_layer.next_layer.next_layer...          -     884.736M  \n",
            "66_skip_layers.next_layer.next_layer.next_layer...      640.0        320.0  \n",
            "67_skip_layers.next_layer.next_layer.next_layer...          -        320.0  \n",
            "68_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "69_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "70_skip_layers.next_layer.next_layer.next_layer...    2.7648M     1.10592G  \n",
            "71_skip_layers.next_layer.next_layer.next_layer...          -     1.10592G  \n",
            "72_skip_layers.next_layer.next_layer.next_layer...      640.0        320.0  \n",
            "73_skip_layers.next_layer.next_layer.next_layer...          -        320.0  \n",
            "74_skip_layers.next_layer.next_layer.next_layer...     81.92k      32.768M  \n",
            "75_skip_layers.next_layer.next_layer.next_layer...          -      32.768M  \n",
            "76_skip_layers.next_layer.next_layer.next_layer...      640.0        320.0  \n",
            "77_skip_layers.next_layer.next_layer.next_layer...          -        320.0  \n",
            "78_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "79_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "80_skip_layers.next_layer.next_layer.next_layer...    2.7648M      276.48M  \n",
            "81_skip_layers.next_layer.next_layer.next_layer...          -      276.48M  \n",
            "82_skip_layers.next_layer.next_layer.next_layer...      640.0        320.0  \n",
            "83_skip_layers.next_layer.next_layer.next_layer...          -        320.0  \n",
            "84_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "85_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "86_skip_layers.next_layer.next_layer.next_layer...    2.7648M      276.48M  \n",
            "87_skip_layers.next_layer.next_layer.next_layer...          -      276.48M  \n",
            "88_skip_layers.next_layer.next_layer.next_layer...      640.0        320.0  \n",
            "89_skip_layers.next_layer.next_layer.next_layer...          -        320.0  \n",
            "90_skip_layers.next_layer.next_layer.next_layer...     102.4k       10.24M  \n",
            "91_skip_layers.next_layer.next_layer.next_layer...          -       10.24M  \n",
            "92_skip_layers.next_layer.next_layer.next_layer...      640.0        320.0  \n",
            "93_skip_layers.next_layer.next_layer.next_layer...          -        320.0  \n",
            "94_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "95_skip_layers.next_layer.next_layer.next_layer...          -            -  \n",
            "96_skip_layers.next_layer.next_layer.next_layer...     409.6k      163.84M  \n",
            "97_skip_layers.next_layer.next_layer.next_layer...          -      163.84M  \n",
            "98_skip_layers.next_layer.next_layer.next_layer...    5.5296M     2.21184G  \n",
            "99_skip_layers.next_layer.next_layer.next_layer...          -     2.21184G  \n",
            "100_skip_layers.next_layer.next_layer.next_laye...      640.0        320.0  \n",
            "101_skip_layers.next_layer.next_layer.next_laye...          -        320.0  \n",
            "102_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "103_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "104_skip_layers.next_layer.next_layer.next_laye...    2.7648M     1.10592G  \n",
            "105_skip_layers.next_layer.next_layer.next_laye...          -     1.10592G  \n",
            "106_skip_layers.next_layer.next_layer.next_laye...      640.0        320.0  \n",
            "107_skip_layers.next_layer.next_layer.next_laye...          -        320.0  \n",
            "108_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "109_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "110_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "111_skip_layers.next_layer.next_layer.next_laye...    327.68k     524.288M  \n",
            "112_skip_layers.next_layer.next_layer.next_laye...          -     524.288M  \n",
            "113_skip_layers.next_layer.next_layer.next_laye...  3.538944M   5.6623104G  \n",
            "114_skip_layers.next_layer.next_layer.next_laye...          -   5.6623104G  \n",
            "115_skip_layers.next_layer.next_layer.next_laye...      512.0        256.0  \n",
            "116_skip_layers.next_layer.next_layer.next_laye...          -        256.0  \n",
            "117_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "118_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "119_skip_layers.next_layer.next_layer.next_laye...  1.769472M   2.8311552G  \n",
            "120_skip_layers.next_layer.next_layer.next_laye...          -   2.8311552G  \n",
            "121_skip_layers.next_layer.next_layer.next_laye...      512.0        256.0  \n",
            "122_skip_layers.next_layer.next_layer.next_laye...          -        256.0  \n",
            "123_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "124_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "125_skip_layers.next_layer.next_layer.next_laye...          -            -  \n",
            "126_skip_layers.next_layer.next_layer.upsample....   262.144k   3.3554432G  \n",
            "127_skip_layers.next_layer.next_layer.upsample....          -   3.3554432G  \n",
            "128_skip_layers.next_layer.next_layer.upsample....   884.736k  11.3246208G  \n",
            "129_skip_layers.next_layer.next_layer.upsample....          -  11.3246208G  \n",
            "130_skip_layers.next_layer.next_layer.upsample....      256.0        128.0  \n",
            "131_skip_layers.next_layer.next_layer.upsample....          -        128.0  \n",
            "132_skip_layers.next_layer.next_layer.upsample....          -            -  \n",
            "133_skip_layers.next_layer.next_layer.upsample....          -            -  \n",
            "134_skip_layers.next_layer.next_layer.upsample....   442.368k   5.6623104G  \n",
            "135_skip_layers.next_layer.next_layer.upsample....          -   5.6623104G  \n",
            "136_skip_layers.next_layer.next_layer.upsample....      256.0        128.0  \n",
            "137_skip_layers.next_layer.next_layer.upsample....          -        128.0  \n",
            "138_skip_layers.next_layer.next_layer.upsample....          -            -  \n",
            "139_skip_layers.next_layer.next_layer.upsample....          -            -  \n",
            "140_skip_layers.next_layer.next_layer.Identity_...          -            -  \n",
            "141_skip_layers.next_layer.upsample.transp_conv...    65.536k   6.7108864G  \n",
            "142_skip_layers.next_layer.upsample.transp_conv...          -   6.7108864G  \n",
            "143_skip_layers.next_layer.upsample.conv_block....   221.184k  22.6492416G  \n",
            "144_skip_layers.next_layer.upsample.conv_block....          -  22.6492416G  \n",
            "145_skip_layers.next_layer.upsample.conv_block....      128.0         64.0  \n",
            "146_skip_layers.next_layer.upsample.conv_block....          -         64.0  \n",
            "147_skip_layers.next_layer.upsample.conv_block....          -            -  \n",
            "148_skip_layers.next_layer.upsample.conv_block....          -            -  \n",
            "149_skip_layers.next_layer.upsample.conv_block....   110.592k  11.3246208G  \n",
            "150_skip_layers.next_layer.upsample.conv_block....          -  11.3246208G  \n",
            "151_skip_layers.next_layer.upsample.conv_block....      128.0         64.0  \n",
            "152_skip_layers.next_layer.upsample.conv_block....          -         64.0  \n",
            "153_skip_layers.next_layer.upsample.conv_block....          -            -  \n",
            "154_skip_layers.next_layer.upsample.conv_block....          -            -  \n",
            "155_skip_layers.next_layer.Identity_super_head              -            -  \n",
            "156_skip_layers.upsample.transp_conv.ConvTransp...    16.384k  13.4217728G  \n",
            "157_skip_layers.upsample.transp_conv.ConvTransp...          -  13.4217728G  \n",
            "158_skip_layers.upsample.conv_block.conv1.Conv3...    55.296k  45.2984832G  \n",
            "159_skip_layers.upsample.conv_block.conv1.Conv3...          -  45.2984832G  \n",
            "160_skip_layers.upsample.conv_block.InstanceNor...       64.0         32.0  \n",
            "161_skip_layers.upsample.conv_block.InstanceNor...          -         32.0  \n",
            "162_skip_layers.upsample.conv_block.LeakyReLU_l...          -            -  \n",
            "163_skip_layers.upsample.conv_block.LeakyReLU_l...          -            -  \n",
            "164_skip_layers.upsample.conv_block.conv2.Conv3...    27.648k  22.6492416G  \n",
            "165_skip_layers.upsample.conv_block.conv2.Conv3...          -  22.6492416G  \n",
            "166_skip_layers.upsample.conv_block.InstanceNor...       64.0         32.0  \n",
            "167_skip_layers.upsample.conv_block.InstanceNor...          -         32.0  \n",
            "168_skip_layers.upsample.conv_block.LeakyReLU_l...          -            -  \n",
            "169_skip_layers.upsample.conv_block.LeakyReLU_l...          -            -  \n",
            "170_skip_layers.Identity_super_head                         -            -  \n",
            "171_output_block.conv.Conv3d_conv                        33.0     26.2144M  \n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "                             Totals\n",
            "Total params             30.681697M\n",
            "Trainable params         30.681697M\n",
            "Non-trainable params            0.0\n",
            "Mult-Adds             421.94617312G\n",
            "=========================================================================================================================================================================\n",
            "out size: torch.Size([1, 1, 160, 160, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "QJfk3q0iB5At",
        "outputId": "0323d159-2007-44e4-b61a-40b4f5796e28"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from init import Options\n",
        "import monai\n",
        "from monai.data import ArrayDataset, GridPatchDataset, create_test_image_3d\n",
        "from monai.transforms import (Compose, LoadImaged, AddChanneld, Transpose, Resized, CropForegroundd, CastToTyped,RandGaussianSmoothd,\n",
        "                              ScaleIntensityd, ToTensord, RandSpatialCropd, Rand3DElasticd, RandAffined, SpatialPadd,\n",
        "    Spacingd, Orientationd, RandZoomd, ThresholdIntensityd, RandShiftIntensityd, RandGaussianNoised, BorderPadd,RandAdjustContrastd, NormalizeIntensityd,RandFlipd, ScaleIntensityRanged)\n",
        "\n",
        "\n",
        "class IndexTracker(object):\n",
        "    def __init__(self, ax, X):\n",
        "        self.ax = ax\n",
        "        ax.set_title('use scroll wheel to navigate images')\n",
        "\n",
        "        self.X = X\n",
        "        rows, cols, self.slices = X.shape\n",
        "        self.ind = self.slices//2\n",
        "\n",
        "        self.im = ax.imshow(self.X[:, :, self.ind],cmap= 'gray')\n",
        "        self.update()\n",
        "\n",
        "    def onscroll(self, event):\n",
        "        print(\"%s %s\" % (event.button, event.step))\n",
        "        if event.button == 'up':\n",
        "            self.ind = (self.ind + 1) % self.slices\n",
        "        else:\n",
        "            self.ind = (self.ind - 1) % self.slices\n",
        "        self.update()\n",
        "\n",
        "    def update(self):\n",
        "        self.im.set_data(self.X[:, :, self.ind])\n",
        "        self.ax.set_ylabel('slice %s' % self.ind)\n",
        "        self.im.axes.figure.canvas.draw()\n",
        "\n",
        "\n",
        "def plot3d(image):\n",
        "    original=image\n",
        "    original = np.rot90(original, k=-1)\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    tracker = IndexTracker(ax, original)\n",
        "    fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    opt = Options().parse()\n",
        "\n",
        "    train_images = sorted(glob(os.path.join(opt.images_folder, '/content/drive/My Drive/Data_folder/images/train', 'image*.nii')))\n",
        "    train_segs = sorted(glob(os.path.join(opt.labels_folder, '/content/drive/My Drive/Data_folder/labels/train', 'label*.nii')))\n",
        "\n",
        "    data_dicts = [{'image': image_name, 'label': label_name}\n",
        "                  for image_name, label_name in zip(train_images, train_segs)]\n",
        "\n",
        "    monai_transforms = [\n",
        "\n",
        "        LoadImaged(keys=['image', 'label']),\n",
        "        AddChanneld(keys=['image', 'label']),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        # ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),\n",
        "        # ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "        CropForegroundd(keys=['image', 'label'], source_key='image', start_coord_key='foreground_start_coord',\n",
        "                        end_coord_key='foreground_end_coord', ),  # crop CropForeground\n",
        "        NormalizeIntensityd(keys=['image']),\n",
        "        ScaleIntensityd(keys=['image']),\n",
        "        # Spacingd(keys=['image', 'label'], pixdim=opt.resolution, mode=('bilinear', 'nearest')),\n",
        "\n",
        "        SpatialPadd(keys=['image', 'label'], spatial_size=opt.patch_size, method= 'end'),\n",
        "        RandSpatialCropd(keys=['image', 'label'], roi_size=opt.patch_size, random_size=False),\n",
        "        ToTensord(keys=['image', 'label','foreground_start_coord', 'foreground_end_coord'],)\n",
        "    ]\n",
        "\n",
        "    transform = Compose(monai_transforms)\n",
        "    check_ds = monai.data.Dataset(data=data_dicts, transform=transform)\n",
        "    loader = DataLoader(check_ds, batch_size=1, shuffle=True, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "    check_data = monai.utils.misc.first(loader)\n",
        "    im, seg, coord1, coord2 = (check_data['image'][0], check_data['label'][0],check_data['foreground_start_coord'][0],\n",
        "                      check_data['foreground_end_coord'][0])\n",
        "\n",
        "    print(im.shape, seg.shape, coord1, coord2)\n",
        "\n",
        "    vol = im[0].numpy()\n",
        "    mask = seg[0].numpy()\n",
        "\n",
        "    print(vol.shape, mask.shape)\n",
        "    plot3d(vol)\n",
        "    plot3d(mask)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 160, 160, 32]) torch.Size([1, 160, 160, 32]) tensor([ 0, 12,  0]) tensor([169, 141, 168])\n",
            "(160, 160, 32) (160, 160, 32)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbkbS1hYM2Ic"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8608aZILSyhZ",
        "outputId": "0332fd98-a06d-4dbc-c4b6-c1a457dba922"
      },
      "source": [
        "\n",
        "\n",
        "from init import Options\n",
        "from networks import *\n",
        "# from networks import build_net\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "from glob import glob\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import monai\n",
        "from monai.data import create_test_image_3d, list_data_collate\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.transforms import (Compose, LoadImaged, AddChanneld, Transpose,Activations,AsDiscrete, RandGaussianSmoothd, CropForegroundd, SpatialPadd,\n",
        "                              ScaleIntensityd, ToTensord, RandSpatialCropd, Rand3DElasticd, RandAffined, RandZoomd,\n",
        "    Spacingd, Orientationd, Resized, ThresholdIntensityd, RandShiftIntensityd, BorderPadd, RandGaussianNoised, RandAdjustContrastd,NormalizeIntensityd,RandFlipd)\n",
        "\n",
        "from monai.visualize import plot_2d_or_3d_image\n",
        "# from monai.engines import get_devices_spec\n",
        "\n",
        "def main():\n",
        "    opt = Options().parse()\n",
        "    # monai.config.print_config()\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "    # check gpus\n",
        "    if opt.gpu_ids != '-1':\n",
        "        num_gpus = len(opt.gpu_ids.split(','))\n",
        "    else:\n",
        "        num_gpus = 0\n",
        "    print('number of GPU:', num_gpus)\n",
        "\n",
        "    # Data loader creation\n",
        "    # train images\n",
        "    train_images = sorted(glob(os.path.join(opt.images_folder, '/content/drive/My Drive/Data_folder/images/train', 'image*.nii')))\n",
        "    train_segs = sorted(glob(os.path.join(opt.labels_folder, '/content/drive/My Drive/Data_folder/labels/train', 'label*.nii')))\n",
        "\n",
        "    train_images_for_dice = sorted(glob(os.path.join(opt.images_folder, '/content/drive/My Drive/Data_folder/images/train', 'image*.nii')))\n",
        "    train_segs_for_dice = sorted(glob(os.path.join(opt.labels_folder, '/content/drive/My Drive/Data_folder/labels/train', 'label*.nii')))\n",
        "\n",
        "    # validation images\n",
        "    val_images = sorted(glob(os.path.join(opt.images_folder, '/content/drive/My Drive/Data_folder/images/val', 'image*.nii')))\n",
        "    val_segs = sorted(glob(os.path.join(opt.labels_folder, '/content/drive/My Drive/Data_folder/labels/val', 'label*.nii')))\n",
        "\n",
        "    # test images\n",
        "    test_images = sorted(glob(os.path.join(opt.images_folder, '/content/drive/My Drive/Data_folder/images/test', 'image*.nii')))\n",
        "    test_segs = sorted(glob(os.path.join(opt.labels_folder, '/content/drive/My Drive/Data_folder/labels/test', 'label*.nii')))\n",
        "\n",
        "    # augment the data list for training\n",
        "    for i in range(int(opt.increase_factor_data)):\n",
        "    \n",
        "        train_images.extend(train_images)\n",
        "        train_segs.extend(train_segs)\n",
        "\n",
        "    print('Number of training patches per epoch:', len(train_images))\n",
        "    print('Number of training images per epoch:', len(train_images_for_dice))\n",
        "    print('Number of validation images per epoch:', len(val_images))\n",
        "    print('Number of test images per epoch:', len(test_images))\n",
        "\n",
        "    # Creation of data directories for data_loader\n",
        "\n",
        "    train_dicts = [{'image': image_name, 'label': label_name}\n",
        "                  for image_name, label_name in zip(train_images, train_segs)]\n",
        "\n",
        "    train_dice_dicts = [{'image': image_name, 'label': label_name}\n",
        "                   for image_name, label_name in zip(train_images_for_dice, train_segs_for_dice)]\n",
        "\n",
        "    val_dicts = [{'image': image_name, 'label': label_name}\n",
        "                   for image_name, label_name in zip(val_images, val_segs)]\n",
        "\n",
        "    test_dicts = [{'image': image_name, 'label': label_name}\n",
        "                 for image_name, label_name in zip(test_images, test_segs)]\n",
        "\n",
        "    # Transforms list\n",
        "\n",
        "    if opt.resolution is not None:\n",
        "        train_transforms = [\n",
        "            LoadImaged(keys=['image', 'label']),\n",
        "            AddChanneld(keys=['image', 'label']),\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),  # CT HU filter\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "            CropForegroundd(keys=['image', 'label'], source_key='image'),               # crop CropForeground\n",
        "\n",
        "            NormalizeIntensityd(keys=['image']),                                          # augmentation\n",
        "            ScaleIntensityd(keys=['image']),                                              # intensity\n",
        "            Spacingd(keys=['image', 'label'], pixdim=opt.resolution, mode=('bilinear', 'nearest')),  # resolution\n",
        "\n",
        "            RandFlipd(keys=['image', 'label'], prob=0.15, spatial_axis=1),\n",
        "            RandFlipd(keys=['image', 'label'], prob=0.15, spatial_axis=0),\n",
        "            RandFlipd(keys=['image', 'label'], prob=0.15, spatial_axis=2),\n",
        "            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                        rotate_range=(np.pi / 36, np.pi / 36, np.pi * 2), padding_mode=\"zeros\"),\n",
        "            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                        rotate_range=(np.pi / 36, np.pi / 2, np.pi / 36), padding_mode=\"zeros\"),\n",
        "            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                        rotate_range=(np.pi / 2, np.pi / 36, np.pi / 36), padding_mode=\"zeros\"),\n",
        "            Rand3DElasticd(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                           sigma_range=(5, 8), magnitude_range=(100, 200), scale_range=(0.15, 0.15, 0.15),\n",
        "                           padding_mode=\"zeros\"),\n",
        "            RandGaussianSmoothd(keys=[\"image\"], sigma_x=(0.5, 1.15), sigma_y=(0.5, 1.15), sigma_z=(0.5, 1.15), prob=0.1,),\n",
        "            RandAdjustContrastd(keys=['image'], gamma=(0.5, 2.5), prob=0.1),\n",
        "            RandGaussianNoised(keys=['image'], prob=0.1, mean=np.random.uniform(0, 0.5), std=np.random.uniform(0, 15)),\n",
        "            RandShiftIntensityd(keys=['image'], offsets=np.random.uniform(0,0.3), prob=0.1),\n",
        "\n",
        "            SpatialPadd(keys=['image', 'label'], spatial_size=opt.patch_size, method= 'end'),  # pad if the image is smaller than patch\n",
        "            RandSpatialCropd(keys=['image', 'label'], roi_size=opt.patch_size, random_size=False),\n",
        "            ToTensord(keys=['image', 'label'])\n",
        "        ]\n",
        "\n",
        "        val_transforms = [\n",
        "            LoadImaged(keys=['image', 'label']),\n",
        "            AddChanneld(keys=['image', 'label']),\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "            CropForegroundd(keys=['image', 'label'], source_key='image'),                   # crop CropForeground\n",
        "\n",
        "            NormalizeIntensityd(keys=['image']),                                      # intensity\n",
        "            ScaleIntensityd(keys=['image']),\n",
        "            Spacingd(keys=['image', 'label'], pixdim=opt.resolution, mode=('bilinear', 'nearest')),  # resolution\n",
        "\n",
        "            SpatialPadd(keys=['image', 'label'], spatial_size=opt.patch_size, method= 'end'),  # pad if the image is smaller than patch\n",
        "            ToTensord(keys=['image', 'label'])\n",
        "        ]\n",
        "    else:\n",
        "        train_transforms = [\n",
        "            LoadImaged(keys=['image', 'label']),\n",
        "            AddChanneld(keys=['image', 'label']),\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "            CropForegroundd(keys=['image', 'label'], source_key='image'),               # crop CropForeground\n",
        "\n",
        "            NormalizeIntensityd(keys=['image']),                                          # augmentation\n",
        "            ScaleIntensityd(keys=['image']),                                              # intensity\n",
        "\n",
        "            RandFlipd(keys=['image', 'label'], prob=0.15, spatial_axis=1),\n",
        "            RandFlipd(keys=['image', 'label'], prob=0.15, spatial_axis=0),\n",
        "            RandFlipd(keys=['image', 'label'], prob=0.15, spatial_axis=2),\n",
        "            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                        rotate_range=(np.pi / 36, np.pi / 36, np.pi * 2), padding_mode=\"zeros\"),\n",
        "            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                        rotate_range=(np.pi / 36, np.pi / 2, np.pi / 36), padding_mode=\"zeros\"),\n",
        "            RandAffined(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                        rotate_range=(np.pi / 2, np.pi / 36, np.pi / 36), padding_mode=\"zeros\"),\n",
        "            Rand3DElasticd(keys=['image', 'label'], mode=('bilinear', 'nearest'), prob=0.1,\n",
        "                           sigma_range=(5, 8), magnitude_range=(100, 200), scale_range=(0.15, 0.15, 0.15),\n",
        "                           padding_mode=\"zeros\"),\n",
        "            RandGaussianSmoothd(keys=[\"image\"], sigma_x=(0.5, 1.15), sigma_y=(0.5, 1.15), sigma_z=(0.5, 1.15), prob=0.1,),\n",
        "            RandAdjustContrastd(keys=['image'], gamma=(0.5, 2.5), prob=0.1),\n",
        "            RandGaussianNoised(keys=['image'], prob=0.1, mean=np.random.uniform(0, 0.5), std=np.random.uniform(0, 1)),\n",
        "            RandShiftIntensityd(keys=['image'], offsets=np.random.uniform(0,0.3), prob=0.1),\n",
        "\n",
        "            SpatialPadd(keys=['image', 'label'], spatial_size=opt.patch_size, method= 'end'),  # pad if the image is smaller than patch\n",
        "            RandSpatialCropd(keys=['image', 'label'], roi_size=opt.patch_size, random_size=False),\n",
        "            ToTensord(keys=['image', 'label'])\n",
        "        ]\n",
        "\n",
        "        val_transforms = [\n",
        "            LoadImaged(keys=['image', 'label']),\n",
        "            AddChanneld(keys=['image', 'label']),\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),\n",
        "            # ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "            CropForegroundd(keys=['image', 'label'], source_key='image'),                   # crop CropForeground\n",
        "\n",
        "            NormalizeIntensityd(keys=['image']),                                      # intensity\n",
        "            ScaleIntensityd(keys=['image']),\n",
        "\n",
        "            SpatialPadd(keys=['image', 'label'], spatial_size=opt.patch_size, method= 'end'),  # pad if the image is smaller than patch\n",
        "            ToTensord(keys=['image', 'label'])\n",
        "        ]\n",
        "\n",
        "    train_transforms = Compose(train_transforms)\n",
        "    val_transforms = Compose(val_transforms)\n",
        "\n",
        "    # create a training data loader\n",
        "    check_train = monai.data.Dataset(data=train_dicts, transform=train_transforms)\n",
        "    train_loader = DataLoader(check_train, batch_size=opt.batch_size, shuffle=True, num_workers=opt.workers, pin_memory=False)\n",
        "\n",
        "    # create a training_dice data loader\n",
        "    check_val = monai.data.Dataset(data=train_dice_dicts, transform=val_transforms)\n",
        "    train_dice_loader = DataLoader(check_val, batch_size=1, num_workers=opt.workers, pin_memory=False)\n",
        "\n",
        "    # create a validation data loader\n",
        "    check_val = monai.data.Dataset(data=val_dicts, transform=val_transforms)\n",
        "    val_loader = DataLoader(check_val, batch_size=1, num_workers=opt.workers, pin_memory=False)\n",
        "\n",
        "    # create a validation data loader\n",
        "    check_val = monai.data.Dataset(data=test_dicts, transform=val_transforms)\n",
        "    test_loader = DataLoader(check_val, batch_size=1, num_workers=opt.workers, pin_memory=False)\n",
        "\n",
        "    # # try to use all the available GPUs\n",
        "    # devices = get_devices_spec(None)\n",
        "\n",
        "    # build the network\n",
        "    net = build_net()\n",
        "    net.cuda()\n",
        "\n",
        "    if num_gpus > 1:\n",
        "        net = torch.nn.DataParallel(net)\n",
        "\n",
        "    if opt.preload is not None:\n",
        "        net.load_state_dict(torch.load(opt.preload))\n",
        "\n",
        "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n",
        "\n",
        "    loss_function = monai.losses.DiceCELoss(sigmoid=True)\n",
        "\n",
        "    optim = torch.optim.SGD(net.parameters(), lr=opt.lr, momentum=0.99, weight_decay=3e-5, nesterov=True,)\n",
        "\n",
        "    net_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optim, lr_lambda=lambda epoch: (1 - epoch / opt.epochs) ** 0.9)\n",
        "\n",
        "    # start a typical PyTorch training\n",
        "    val_interval = 1\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    epoch_loss_values = list()\n",
        "    metric_values = list()\n",
        "    writer = SummaryWriter()\n",
        "    for epoch in range(opt.epochs):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{opt.epochs}\")\n",
        "        net.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[\"image\"].cuda(), batch_data[\"label\"].cuda()\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_len = len(check_train) // train_loader.batch_size\n",
        "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "        update_learning_rate(net_scheduler, optim)\n",
        "\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            net.eval()\n",
        "            with torch.no_grad():\n",
        "\n",
        "                def plot_dice(images_loader):\n",
        "\n",
        "                    metric_sum = 0.0\n",
        "                    metric_count = 0\n",
        "                    val_images = None\n",
        "                    val_labels = None\n",
        "                    val_outputs = None\n",
        "                    for data in images_loader:\n",
        "                        val_images, val_labels = data[\"image\"].cuda(), data[\"label\"].cuda()\n",
        "                        roi_size = opt.patch_size\n",
        "                        sw_batch_size = 4\n",
        "                        val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, net)\n",
        "                        val_outputs = post_trans(val_outputs)\n",
        "                        value = dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                        metric_count += len(value)\n",
        "                        metric_sum += value.item() * len(value)\n",
        "                    metric = metric_sum / metric_count\n",
        "                    metric_values.append(metric)\n",
        "                    return metric, val_images, val_labels, val_outputs\n",
        "\n",
        "                metric, val_images, val_labels, val_outputs = plot_dice(val_loader)\n",
        "\n",
        "                # Save best model\n",
        "                if metric > best_metric:\n",
        "                    best_metric = metric\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(net.state_dict(), \"best_metric_model.pth\")\n",
        "                    print(\"saved new best metric model\")\n",
        "\n",
        "                metric_train, train_images, train_labels, train_outputs = plot_dice(train_dice_loader)\n",
        "                metric_test, test_images, test_labels, test_outputs = plot_dice(test_loader)\n",
        "\n",
        "                # Logger bar\n",
        "                print(\n",
        "                    \"current epoch: {} Training dice: {:.4f} Validation dice: {:.4f} Testing dice: {:.4f} Best Validation dice: {:.4f} at epoch {}\".format(\n",
        "                        epoch + 1, metric_train, metric, metric_test, best_metric, best_metric_epoch\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                writer.add_scalar(\"Mean_epoch_loss\", epoch_loss, epoch + 1)\n",
        "                writer.add_scalar(\"Testing_dice\", metric_test, epoch + 1)\n",
        "                writer.add_scalar(\"Training_dice\", metric_train, epoch + 1)\n",
        "                writer.add_scalar(\"Validation_dice\", metric, epoch + 1)\n",
        "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
        "                # val_outputs = (val_outputs.sigmoid() >= 0.5).float()\n",
        "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"validation image\")\n",
        "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"validation label\")\n",
        "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"validation inference\")\n",
        "                plot_2d_or_3d_image(test_images, epoch + 1, writer, index=0, tag=\"test image\")\n",
        "                plot_2d_or_3d_image(test_labels, epoch + 1, writer, index=0, tag=\"test label\")\n",
        "                plot_2d_or_3d_image(test_outputs, epoch + 1, writer, index=0, tag=\"test inference\")\n",
        "\n",
        "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of GPU: 2\n",
            "Number of training patches per epoch: 26\n",
            "Number of training images per epoch: 13\n",
            "Number of validation images per epoch: 6\n",
            "Number of test images per epoch: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------\n",
            "epoch 1/1000\n",
            "1/6, train_loss: 0.9992\n",
            "2/6, train_loss: 0.9956\n",
            "3/6, train_loss: 0.9785\n",
            "4/6, train_loss: 0.9952\n",
            "5/6, train_loss: 0.9998\n",
            "6/6, train_loss: 1.0000\n",
            "7/6, train_loss: 0.9972\n",
            "epoch 1 average loss: 0.9951\n",
            "saved new best metric model\n",
            "current epoch: 1 Training dice: 0.0039 Validation dice: 0.0004 Testing dice: 0.0013 Best Validation dice: 0.0004 at epoch 1\n",
            "----------\n",
            "epoch 2/1000\n",
            "1/6, train_loss: 0.9987\n",
            "2/6, train_loss: 1.0000\n",
            "3/6, train_loss: 0.9998\n",
            "4/6, train_loss: 0.9601\n",
            "5/6, train_loss: 1.0000\n",
            "6/6, train_loss: 1.0000\n",
            "7/6, train_loss: 1.0000\n",
            "epoch 2 average loss: 0.9941\n",
            "saved new best metric model\n",
            "current epoch: 2 Training dice: 0.0046 Validation dice: 0.0006 Testing dice: 0.0016 Best Validation dice: 0.0006 at epoch 2\n",
            "----------\n",
            "epoch 3/1000\n",
            "1/6, train_loss: 0.9982\n",
            "2/6, train_loss: 1.0000\n",
            "3/6, train_loss: 0.9152\n",
            "4/6, train_loss: 1.0000\n",
            "5/6, train_loss: 0.9951\n",
            "6/6, train_loss: 0.9970\n",
            "7/6, train_loss: 1.0000\n",
            "epoch 3 average loss: 0.9865\n",
            "saved new best metric model\n",
            "current epoch: 3 Training dice: 0.0062 Validation dice: 0.0008 Testing dice: 0.0024 Best Validation dice: 0.0008 at epoch 3\n",
            "----------\n",
            "epoch 4/1000\n",
            "1/6, train_loss: 0.9962\n",
            "2/6, train_loss: 0.9603\n",
            "3/6, train_loss: 0.9990\n",
            "4/6, train_loss: 1.0000\n",
            "5/6, train_loss: 0.9968\n",
            "6/6, train_loss: 0.9752\n",
            "7/6, train_loss: 1.0000\n",
            "epoch 4 average loss: 0.9896\n",
            "saved new best metric model\n",
            "current epoch: 4 Training dice: 0.0085 Validation dice: 0.0011 Testing dice: 0.0031 Best Validation dice: 0.0011 at epoch 4\n",
            "----------\n",
            "epoch 5/1000\n",
            "1/6, train_loss: 0.9998\n",
            "2/6, train_loss: 0.9976\n",
            "3/6, train_loss: 1.0000\n",
            "4/6, train_loss: 0.9975\n",
            "5/6, train_loss: 1.0000\n",
            "6/6, train_loss: 1.0000\n",
            "7/6, train_loss: 1.0000\n",
            "epoch 5 average loss: 0.9993\n",
            "saved new best metric model\n",
            "current epoch: 5 Training dice: 0.0088 Validation dice: 0.0012 Testing dice: 0.0033 Best Validation dice: 0.0012 at epoch 5\n",
            "----------\n",
            "epoch 6/1000\n",
            "1/6, train_loss: 1.0000\n",
            "2/6, train_loss: 0.9774\n",
            "3/6, train_loss: 0.9996\n",
            "4/6, train_loss: 0.9970\n",
            "5/6, train_loss: 0.9989\n",
            "6/6, train_loss: 0.9967\n",
            "7/6, train_loss: 0.9990\n",
            "epoch 6 average loss: 0.9955\n",
            "saved new best metric model\n",
            "current epoch: 6 Training dice: 0.0088 Validation dice: 0.0012 Testing dice: 0.0034 Best Validation dice: 0.0012 at epoch 6\n",
            "----------\n",
            "epoch 7/1000\n",
            "1/6, train_loss: 0.9775\n",
            "2/6, train_loss: 0.9983\n",
            "3/6, train_loss: 0.9998\n",
            "4/6, train_loss: 0.9727\n",
            "5/6, train_loss: 1.0000\n",
            "6/6, train_loss: 0.9991\n",
            "7/6, train_loss: 0.9997\n",
            "epoch 7 average loss: 0.9925\n",
            "saved new best metric model\n",
            "current epoch: 7 Training dice: 0.0090 Validation dice: 0.0013 Testing dice: 0.0034 Best Validation dice: 0.0013 at epoch 7\n",
            "----------\n",
            "epoch 8/1000\n",
            "1/6, train_loss: 1.0000\n",
            "2/6, train_loss: 0.9992\n",
            "3/6, train_loss: 0.9995\n",
            "4/6, train_loss: 1.0000\n",
            "5/6, train_loss: 0.9552\n",
            "6/6, train_loss: 0.9964\n",
            "7/6, train_loss: 1.0000\n",
            "epoch 8 average loss: 0.9929\n",
            "saved new best metric model\n",
            "current epoch: 8 Training dice: 0.0091 Validation dice: 0.0013 Testing dice: 0.0035 Best Validation dice: 0.0013 at epoch 8\n",
            "----------\n",
            "epoch 9/1000\n",
            "1/6, train_loss: 0.9968\n",
            "2/6, train_loss: 0.9967\n",
            "3/6, train_loss: 0.9988\n",
            "4/6, train_loss: 0.9990\n",
            "5/6, train_loss: 1.0000\n",
            "6/6, train_loss: 0.9998\n",
            "7/6, train_loss: 0.9542\n",
            "epoch 9 average loss: 0.9922\n",
            "saved new best metric model\n",
            "current epoch: 9 Training dice: 0.0091 Validation dice: 0.0013 Testing dice: 0.0035 Best Validation dice: 0.0013 at epoch 9\n",
            "----------\n",
            "epoch 10/1000\n",
            "1/6, train_loss: 0.9983\n",
            "2/6, train_loss: 1.0000\n",
            "3/6, train_loss: 0.9992\n",
            "4/6, train_loss: 0.9980\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bdfa1b863dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-bdfa1b863dfc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/networks/nets/dynunet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_supervision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/networks/nets/dynunet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdownout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mnextout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mupout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuper_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/networks/blocks/dynunet_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, skip)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransp_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/monai/networks/blocks/dynunet_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    581\u001b[0m             )\n\u001b[1;32m    582\u001b[0m         return F.conv3d(\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         )\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "ipIP5XX7Egh1",
        "outputId": "68eb752a-21d3-44d8-d9c2-ac09cdce2887"
      },
      "source": [
        "from utils import *\n",
        "import argparse\n",
        "from networks import *\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.data import NiftiSaver, create_test_image_3d, list_data_collate\n",
        "\n",
        "\n",
        "def segment(image, label, result, weights, resolution, patch_size, gpu_ids):\n",
        "\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "    if label is not None:\n",
        "        uniform_img_dimensions_internal(image, label, True)\n",
        "        files = [{\"image\": image, \"label\": label}]\n",
        "    else:\n",
        "        files = [{\"image\": image}]\n",
        "\n",
        "    # original size, size after crop_background, cropped roi coordinates, cropped resampled roi size\n",
        "    original_shape, crop_shape, coord1, coord2, resampled_size, original_resolution = statistics_crop(image, resolution)\n",
        "\n",
        "    # -------------------------------\n",
        "\n",
        "    if label is not None:\n",
        "        if resolution is not None:\n",
        "\n",
        "            val_transforms = Compose([\n",
        "                LoadImaged(keys=['image', 'label']),\n",
        "                AddChanneld(keys=['image', 'label']),\n",
        "                ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),  # Threshold CT\n",
        "                ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "                CropForegroundd(keys=['image', 'label'], source_key='image'),  # crop CropForeground\n",
        "\n",
        "                NormalizeIntensityd(keys=['image']),  # intensity\n",
        "                ScaleIntensityd(keys=['image']),\n",
        "                Spacingd(keys=['image', 'label'], pixdim=resolution, mode=('bilinear', 'nearest')),  # resolution\n",
        "\n",
        "                SpatialPadd(keys=['image', 'label'], spatial_size=patch_size, method= 'end'),\n",
        "                ToTensord(keys=['image', 'label'])])\n",
        "        else:\n",
        "\n",
        "            val_transforms = Compose([\n",
        "                LoadImaged(keys=['image', 'label']),\n",
        "                AddChanneld(keys=['image', 'label']),\n",
        "                ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),  # Threshold CT\n",
        "                ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "                CropForegroundd(keys=['image', 'label'], source_key='image'),  # crop CropForeground\n",
        "\n",
        "                NormalizeIntensityd(keys=['image']),  # intensity\n",
        "                ScaleIntensityd(keys=['image']),\n",
        "\n",
        "                SpatialPadd(keys=['image', 'label'], spatial_size=patch_size, method='end'),  # pad if the image is smaller than patch\n",
        "                ToTensord(keys=['image', 'label'])])\n",
        "\n",
        "    else:\n",
        "        if resolution is not None:\n",
        "\n",
        "            val_transforms = Compose([\n",
        "                LoadImaged(keys=['image']),\n",
        "                AddChanneld(keys=['image']),\n",
        "                ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),  # Threshold CT\n",
        "                ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "                CropForegroundd(keys=['image'], source_key='image'),  # crop CropForeground\n",
        "\n",
        "                NormalizeIntensityd(keys=['image']),  # intensity\n",
        "                ScaleIntensityd(keys=['image']),\n",
        "                Spacingd(keys=['image'], pixdim=resolution, mode=('bilinear')),  # resolution\n",
        "\n",
        "                SpatialPadd(keys=['image'], spatial_size=patch_size, method= 'end'),  # pad if the image is smaller than patch\n",
        "                ToTensord(keys=['image'])])\n",
        "        else:\n",
        "\n",
        "            val_transforms = Compose([\n",
        "                LoadImaged(keys=['image']),\n",
        "                AddChanneld(keys=['image']),\n",
        "                ThresholdIntensityd(keys=['image'], threshold=-135, above=True, cval=-135),  # Threshold CT\n",
        "                ThresholdIntensityd(keys=['image'], threshold=215, above=False, cval=215),\n",
        "                CropForegroundd(keys=['image'], source_key='image'),  # crop CropForeground\n",
        "\n",
        "                NormalizeIntensityd(keys=['image']),  # intensity\n",
        "                ScaleIntensityd(keys=['image']),\n",
        "\n",
        "                SpatialPadd(keys=['image'], spatial_size=patch_size, method='end'), # pad if the image is smaller than patch\n",
        "                ToTensord(keys=['image'])])\n",
        "\n",
        "    val_ds = monai.data.Dataset(data=files, transform=val_transforms)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=0, collate_fn=list_data_collate, pin_memory=False)\n",
        "\n",
        "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n",
        "\n",
        "    if gpu_ids != '-1':\n",
        "\n",
        "        # try to use all the available GPUs\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = gpu_ids\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    net = build_net()\n",
        "    net = net.to(device)\n",
        "\n",
        "    if gpu_ids == '-1':\n",
        "\n",
        "        net.load_state_dict(new_state_dict_cpu(weights))\n",
        "\n",
        "    else:\n",
        "\n",
        "        net.load_state_dict(new_state_dict(weights))\n",
        "\n",
        "    # define sliding window size and batch size for windows inference\n",
        "    roi_size = patch_size\n",
        "    sw_batch_size = 4\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        if label is None:\n",
        "            for val_data in val_loader:\n",
        "                val_images = val_data[\"image\"].cuda()\n",
        "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, net)\n",
        "                val_outputs = post_trans(val_outputs)\n",
        "                # val_outputs = (val_outputs.sigmoid() >= 0.5).float()\n",
        "\n",
        "        else:\n",
        "            metric_sum = 0.0\n",
        "            metric_count = 0\n",
        "            for val_data in val_loader:\n",
        "                val_images, val_labels = val_data[\"image\"].cuda(), val_data[\"label\"].cuda()\n",
        "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, net)\n",
        "                val_outputs = post_trans(val_outputs)\n",
        "                value, _ = dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                metric_count += len(value)\n",
        "                metric_sum += value.item() * len(value)\n",
        "                # val_outputs = (val_outputs.sigmoid() >= 0.5).float()\n",
        "\n",
        "            metric = metric_sum / metric_count\n",
        "            print(\"Evaluation Metric (Dice):\", metric)\n",
        "\n",
        "        result_array = val_outputs.squeeze().data.cpu().numpy()\n",
        "        # Remove the pad if the image was smaller than the patch in some directions\n",
        "        result_array = result_array[0:resampled_size[0],0:resampled_size[1],0:resampled_size[2]]\n",
        "\n",
        "        # resample back to the original resolution\n",
        "        if resolution is not None:\n",
        "\n",
        "            result_array_np = np.transpose(result_array, (2, 1, 0))\n",
        "            result_array_temp = sitk.GetImageFromArray(result_array_np)\n",
        "            result_array_temp.SetSpacing(resolution)\n",
        "\n",
        "            # save temporary label\n",
        "            writer = sitk.ImageFileWriter()\n",
        "            writer.SetFileName('temp_seg.nii')\n",
        "            writer.Execute(result_array_temp)\n",
        "\n",
        "            files = [{\"image\": 'temp_seg.nii'}]\n",
        "\n",
        "            files_transforms = Compose([\n",
        "                LoadImaged(keys=['image']),\n",
        "                AddChanneld(keys=['image']),\n",
        "                Spacingd(keys=['image'], pixdim=original_resolution, mode=('nearest')),\n",
        "                Resized(keys=['image'], spatial_size=crop_shape, mode=('nearest')),\n",
        "            ])\n",
        "\n",
        "            files_ds = Dataset(data=files, transform=files_transforms)\n",
        "            files_loader = DataLoader(files_ds, batch_size=1, num_workers=0)\n",
        "\n",
        "            for files_data in files_loader:\n",
        "                files_images = files_data[\"image\"]\n",
        "\n",
        "                res = files_images.squeeze().data.numpy()\n",
        "\n",
        "            result_array = np.rint(res)\n",
        "\n",
        "            os.remove('./temp_seg.nii')\n",
        "\n",
        "        # recover the cropped background before saving the image\n",
        "        empty_array = np.zeros(original_shape)\n",
        "        empty_array[coord1[0]:coord2[0],coord1[1]:coord2[1],coord1[2]:coord2[2]] = result_array\n",
        "\n",
        "        result_seg = from_numpy_to_itk(empty_array, image)\n",
        "\n",
        "        # save label\n",
        "        writer = sitk.ImageFileWriter()\n",
        "        writer.SetFileName(result)\n",
        "        writer.Execute(result_seg)\n",
        "        print(\"Saved Result at:\", str(result))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--image\", type=str, default='/content/drive/My Drive/Data_folder/images/train/image13.nii', help='source image' )\n",
        "    parser.add_argument(\"--label\", type=str, default=None, help='source label, if you want to compute dice. None for new case')\n",
        "    parser.add_argument(\"--result\", type=str, default='/content/drive/My Drive/Data_folder/test_2.nii', help='path to the .nii result to save')\n",
        "    parser.add_argument(\"--weights\", type=str, default='/content/best_metric_model.pth', help='network weights to load')\n",
        "    parser.add_argument(\"--resolution\", default=[2.25, 2.25, 3], help='Resolution used in training phase')\n",
        "    parser.add_argument(\"--patch_size\", type=int, nargs=3, default=(160, 160, 32), help=\"Input dimension for the generator, same of training\")\n",
        "    parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    segment(args.image, args.label, args.result, args.weights, args.resolution, args.patch_size, args.gpu_ids)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--image IMAGE] [--label LABEL]\n",
            "                             [--result RESULT] [--weights WEIGHTS]\n",
            "                             [--resolution RESOLUTION]\n",
            "                             [--patch_size PATCH_SIZE PATCH_SIZE PATCH_SIZE]\n",
            "                             [--gpu_ids GPU_IDS]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-7ee33397-119d-4321-9de0-2b4589603f65.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "To exit: use 'exit', 'quit', or Ctrl-D.\n"
          ]
        }
      ]
    }
  ]
}
